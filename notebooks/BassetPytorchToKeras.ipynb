{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AvantiShri/colab_notebooks/blob/master/AdaptDeepSEAvariableInputLength.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from functools import reduce\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class LambdaBase(nn.Sequential):\n",
    "    def __init__(self, fn, *args):\n",
    "        super(LambdaBase, self).__init__(*args)\n",
    "        self.lambda_func = fn\n",
    "\n",
    "    def forward_prepare(self, input):\n",
    "        output = []\n",
    "        for module in self._modules.values():\n",
    "            output.append(module(input))\n",
    "        return output if output else input\n",
    "\n",
    "class Lambda(LambdaBase):\n",
    "    def forward(self, input):\n",
    "        return self.lambda_func(self.forward_prepare(input))\n",
    "\n",
    "class LambdaMap(LambdaBase):\n",
    "    def forward(self, input):\n",
    "        return list(map(self.lambda_func,self.forward_prepare(input)))\n",
    "\n",
    "class LambdaReduce(LambdaBase):\n",
    "    def forward(self, input):\n",
    "        return reduce(self.lambda_func,self.forward_prepare(input))\n",
    "\n",
    "def get_model(load_weights = True):\n",
    "    # alphabet seems to be fine:\n",
    "    \"\"\"\n",
    "    https://github.com/davek44/Basset/tree/master/src/dna_io.py#L145-L148\n",
    "    seq = seq.replace('A','0')\n",
    "    seq = seq.replace('C','1')\n",
    "    seq = seq.replace('G','2')\n",
    "    seq = seq.replace('T','3')\n",
    "    \"\"\"\n",
    "    pretrained_model_reloaded_th = nn.Sequential( # Sequential,\n",
    "        nn.Conv2d(4,300,(19, 1)),\n",
    "        nn.BatchNorm2d(300),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((3, 1),(3, 1)),\n",
    "        nn.Conv2d(300,200,(11, 1)),\n",
    "        nn.BatchNorm2d(200),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((4, 1),(4, 1)),\n",
    "        nn.Conv2d(200,200,(7, 1)),\n",
    "        nn.BatchNorm2d(200),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((4, 1),(4, 1)),\n",
    "        Lambda(lambda x: x.view(x.size(0),-1)), # Reshape,\n",
    "        nn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2000,1000)), # Linear,\n",
    "        nn.BatchNorm1d(1000,1e-05,0.1,True),#BatchNorm1d,\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(1000,1000)), # Linear,\n",
    "        nn.BatchNorm1d(1000,1e-05,0.1,True),#BatchNorm1d,\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(1000,164)), # Linear,\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "    if load_weights:\n",
    "        sd = torch.load('/users/eprakash/pretrained_model_reloaded_th.pth')\n",
    "        pretrained_model_reloaded_th.load_state_dict(sd)\n",
    "    return  pretrained_model_reloaded_th\n",
    "\n",
    "model = get_model(load_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight torch.Size([300, 4, 19, 1])\n",
      "0.bias torch.Size([300])\n",
      "1.weight torch.Size([300])\n",
      "1.bias torch.Size([300])\n",
      "4.weight torch.Size([200, 300, 11, 1])\n",
      "4.bias torch.Size([200])\n",
      "5.weight torch.Size([200])\n",
      "5.bias torch.Size([200])\n",
      "8.weight torch.Size([200, 200, 7, 1])\n",
      "8.bias torch.Size([200])\n",
      "9.weight torch.Size([200])\n",
      "9.bias torch.Size([200])\n",
      "13.1.weight torch.Size([1000, 2000])\n",
      "13.1.bias torch.Size([1000])\n",
      "14.weight torch.Size([1000])\n",
      "14.bias torch.Size([1000])\n",
      "17.1.weight torch.Size([1000, 1000])\n",
      "17.1.bias torch.Size([1000])\n",
      "18.weight torch.Size([1000])\n",
      "18.bias torch.Size([1000])\n",
      "21.1.weight torch.Size([164, 1000])\n",
      "21.1.bias torch.Size([164])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/eprakash/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /users/eprakash/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dense, Flatten, Activation, Permute, Flatten, Dropout\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "\n",
    "\n",
    "keras_model = Sequential()\n",
    "keras_model.add(Conv1D(filters=300, kernel_size=19, strides=1, padding=\"valid\", batch_input_shape=(None, 600, 4))) #Change to 400\n",
    "keras_model.add(BatchNormalization(epsilon=1e-05, momentum=0.1))\n",
    "keras_model.add(Activation(\"relu\"))\n",
    "keras_model.add(MaxPooling1D(pool_size=3, strides=3, padding=\"valid\"))\n",
    "keras_model.add(Conv1D(filters=200, kernel_size=11, strides=1, padding=\"valid\"))\n",
    "keras_model.add(BatchNormalization(epsilon=1e-05, momentum=0.1))\n",
    "keras_model.add(Activation(\"relu\"))\n",
    "keras_model.add(MaxPooling1D(pool_size=4, strides=4, padding=\"valid\"))\n",
    "keras_model.add(Conv1D(filters=200, kernel_size=7, strides=1, padding=\"valid\"))\n",
    "keras_model.add(BatchNormalization(epsilon=1e-05, momentum=0.1))\n",
    "keras_model.add(Activation(\"relu\"))\n",
    "keras_model.add(MaxPooling1D(pool_size=4, strides=4, padding=\"valid\"))\n",
    "keras_model.add(Permute((2,1))) #Remove\n",
    "keras_model.add(Flatten())\n",
    "keras_model.add(Dense(1000))\n",
    "keras_model.add(BatchNormalization(epsilon=1e-05, momentum=0.1))\n",
    "keras_model.add(Activation(\"relu\"))\n",
    "keras_model.add(Dropout(0.3))\n",
    "keras_model.add(Dense(1000))\n",
    "keras_model.add(BatchNormalization(epsilon=1e-05, momentum=0.1))\n",
    "keras_model.add(Activation(\"relu\"))\n",
    "keras_model.add(Dropout(0.3))\n",
    "keras_model.add(Dense(164)) #Change to 1 \n",
    "keras_model.add(Activation(\"sigmoid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 582, 300)          23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 582, 300)          1200      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 582, 300)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 194, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 184, 200)          660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 184, 200)          800       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 184, 200)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 46, 200)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 40, 200)           280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 40, 200)           800       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 40, 200)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "permute_1 (Permute)          (None, 200, 10)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              2001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 164)               164164    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 164)               0         \n",
      "=================================================================\n",
      "Total params: 4,140,464\n",
      "Trainable params: 4,135,064\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 weights shape (19, 4, 300)\n",
      "conv1 bias shape (300,)\n",
      "batchnorm1 weights shape (300,)\n",
      "batchnorm1 bias shape (300,)\n",
      "conv2 weights shape (11, 300, 200)\n",
      "conv2 bias shape (200,)\n",
      "batchnorm2 weights shape (200,)\n",
      "batchnorm2 bias shape (200,)\n",
      "conv3 weights shape (7, 200, 200)\n",
      "conv3 bias shape (200,)\n",
      "batchnorm3 weights shape (200,)\n",
      "batchnorm3 bias shape (200,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "conv1_weights = (list(model.children())[0].weight.detach().cpu().numpy().squeeze()).transpose((2,1,0))\n",
    "conv1_bias = (list(model.children())[0].bias.detach().cpu().numpy())\n",
    "print(\"conv1 weights shape\", conv1_weights.shape)\n",
    "print(\"conv1 bias shape\", conv1_bias.shape)\n",
    "keras_model.layers[0].set_weights([conv1_weights, conv1_bias])\n",
    "\n",
    "batchnorm1_gamma = (list(model.children())[1].weight.detach().cpu().numpy().squeeze())\n",
    "batchnorm1_beta = (list(model.children())[1].bias.detach().cpu().numpy())\n",
    "batchnorm1_mean = list(model.children())[1].running_mean\n",
    "batchnorm1_var = list(model.children())[1].running_var.numpy().transpose()\n",
    "print(\"batchnorm1 weights shape\", batchnorm1_gamma.shape)\n",
    "print(\"batchnorm1 bias shape\", batchnorm1_beta.shape)\n",
    "keras_model.layers[1].set_weights([batchnorm1_gamma, batchnorm1_beta, batchnorm1_mean, batchnorm1_var])\n",
    "\n",
    "conv2_weights = (list(model.children())[4].weight.detach().cpu().numpy().squeeze()).transpose((2,1,0))\n",
    "conv2_bias = (list(model.children())[4].bias.detach().cpu().numpy())\n",
    "print(\"conv2 weights shape\", conv2_weights.shape)\n",
    "print(\"conv2 bias shape\", conv2_bias.shape)\n",
    "keras_model.layers[4].set_weights([conv2_weights, conv2_bias])\n",
    "\n",
    "batchnorm2_gamma = (list(model.children())[5].weight.detach().cpu().numpy().squeeze())\n",
    "batchnorm2_beta = (list(model.children())[5].bias.detach().cpu().numpy())\n",
    "batchnorm2_mean = list(model.children())[5].running_mean\n",
    "batchnorm2_var = list(model.children())[5].running_var.numpy().transpose()\n",
    "print(\"batchnorm2 weights shape\", batchnorm2_gamma.shape)\n",
    "print(\"batchnorm2 bias shape\", batchnorm2_beta.shape)\n",
    "keras_model.layers[5].set_weights([batchnorm2_gamma, batchnorm2_beta, batchnorm2_mean, batchnorm2_var])\n",
    "\n",
    "conv3_weights = (list(model.children())[8].weight.detach().cpu().numpy().squeeze()).transpose((2,1,0))\n",
    "conv3_bias = (list(model.children())[8].bias.detach().cpu().numpy())\n",
    "print(\"conv3 weights shape\", conv3_weights.shape)\n",
    "print(\"conv3 bias shape\", conv3_bias.shape)\n",
    "keras_model.layers[8].set_weights([conv3_weights, conv3_bias])\n",
    "\n",
    "batchnorm3_gamma = (list(model.children())[9].weight.detach().cpu().numpy().squeeze())\n",
    "batchnorm3_beta = (list(model.children())[9].bias.detach().cpu().numpy())\n",
    "batchnorm3_mean = list(model.children())[9].running_mean\n",
    "batchnorm3_var = list(model.children())[9].running_var.numpy().transpose()\n",
    "print(\"batchnorm3 weights shape\", batchnorm3_gamma.shape)\n",
    "print(\"batchnorm3 bias shape\", batchnorm3_beta.shape)\n",
    "keras_model.layers[9].set_weights([batchnorm3_gamma, batchnorm3_beta, batchnorm3_mean, batchnorm3_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense1 weights shape (2000, 1000)\n",
      "dense1 bias shape (1000,)\n",
      "(1000,)\n",
      "batchnorm4 weights shape (1000,)\n",
      "batchnorm4 bias shape (1000,)\n",
      "dense2 weights shape (1000, 1000)\n",
      "dense2 bias shape (1000,)\n",
      "(1000,)\n",
      "batchnorm5 weights shape (1000,)\n",
      "batchnorm5 bias shape (1000,)\n",
      "dense3 weights shape (1000, 164)\n",
      "dense3 bias shape (164,)\n"
     ]
    }
   ],
   "source": [
    "dense1_weights = (list(list(model.children())[13].children())[1].weight.detach().cpu().numpy().squeeze()).transpose((1,0))\n",
    "dense1_bias = (list(list(model.children())[13].children())[1].bias.detach().cpu().numpy())\n",
    "#dense1_weights = dense1_weights[500:1500,:]\n",
    "#dense1_weights = dense1_weights.reshape((200,5,1000)).transpose((1,0,2)).reshape((1000,1000))\n",
    "print(\"dense1 weights shape\", dense1_weights.shape)\n",
    "print(\"dense1 bias shape\", dense1_bias.shape)\n",
    "keras_model.layers[14].set_weights([dense1_weights, dense1_bias])\n",
    "\n",
    "batchnorm4_gamma = (list(model.children())[14].weight.detach().cpu().numpy().squeeze())\n",
    "batchnorm4_beta = (list(model.children())[14].bias.detach().cpu().numpy())\n",
    "batchnorm4_mean = list(model.children())[14].running_mean\n",
    "batchnorm4_var = list(model.children())[14].running_var.numpy().transpose()\n",
    "print(batchnorm4_var.shape)\n",
    "print(\"batchnorm4 weights shape\", batchnorm4_gamma.shape)\n",
    "print(\"batchnorm4 bias shape\", batchnorm4_beta.shape)\n",
    "keras_model.layers[15].set_weights([batchnorm4_gamma, batchnorm4_beta, batchnorm4_mean, batchnorm4_var])\n",
    "\n",
    "dense2_weights = (list(list(model.children())[17].children())[1].weight.detach().cpu().numpy().squeeze()).transpose((1,0))\n",
    "dense2_bias = (list(list(model.children())[17].children())[1].bias.detach().cpu().numpy())\n",
    "print(\"dense2 weights shape\", dense2_weights.shape)\n",
    "print(\"dense2 bias shape\", dense2_bias.shape)\n",
    "keras_model.layers[18].set_weights([dense2_weights, dense2_bias])\n",
    "\n",
    "batchnorm5_gamma = (list(model.children())[18].weight.detach().cpu().numpy().squeeze())\n",
    "batchnorm5_beta = (list(model.children())[18].bias.detach().cpu().numpy())\n",
    "batchnorm5_mean = list(model.children())[18].running_mean\n",
    "batchnorm5_var = list(model.children())[18].running_var.numpy().transpose()\n",
    "print(batchnorm5_var.shape)\n",
    "print(\"batchnorm5 weights shape\", batchnorm5_gamma.shape)\n",
    "print(\"batchnorm5 bias shape\", batchnorm5_beta.shape)\n",
    "keras_model.layers[19].set_weights([batchnorm5_gamma, batchnorm5_beta, batchnorm5_mean, batchnorm5_var])\n",
    "\n",
    "dense3_weights = (list(list(model.children())[21].children())[1].weight.detach().cpu().numpy().squeeze()).transpose((1,0))\n",
    "dense3_bias = (list(list(model.children())[21].children())[1].bias.detach().cpu().numpy())\n",
    "print(\"dense3 weights shape\", dense3_weights.shape)\n",
    "print(\"dense3 bias shape\", dense3_bias.shape)\n",
    "keras_model.layers[22].set_weights([dense3_weights, dense3_bias])\n",
    "\n",
    "keras_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "foPoQ8RpzQNa",
    "outputId": "c862b800-41d6-4c40-ff65-a6d3e5456bce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 582, 300)          23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 582, 300)          1200      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 582, 300)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 194, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 184, 200)          660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 184, 200)          800       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 184, 200)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 46, 200)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 40, 200)           280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 40, 200)           800       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 40, 200)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "permute_1 (Permute)          (None, 200, 10)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              2001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 164)               164164    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 164)               0         \n",
      "=================================================================\n",
      "Total params: 4,140,464\n",
      "Trainable params: 4,135,064\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras_model.save('basset.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4, 600, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "inp = np.random.random((10, 4, 600, 1))\n",
    "\n",
    "#onehot encode\n",
    "inp = (inp==np.max(inp,axis=1)[:,None,:,:]).astype(\"float32\")\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pytorch_preds(list_of_layers, the_input):\n",
    "    for layer in list_of_layers:\n",
    "        the_input = layer.eval().forward(the_input)\n",
    "    return the_input\n",
    "\n",
    "pytorch_predictions = get_pytorch_preds(\n",
    "    list_of_layers=list(model.children()),\n",
    "    the_input=torch.from_numpy(inp.astype(\"float32\"))).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/eprakash/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#intermediate_keras=keras.Model(inputs=keras_model.input, outputs=keras_model.layers[1].output)\n",
    "keras_preds = keras_model.predict(inp.squeeze().transpose((0, 2, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 164)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 164)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.1525574e-07"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(pytorch_predictions-keras_preds))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "include_colab_link": true,
   "name": "AdaptDeepSEAvariableInputLength.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
