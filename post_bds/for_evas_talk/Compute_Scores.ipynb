{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import keras\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\r\n"
     ]
    }
   ],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_to_corefiles = {\n",
    "    'HepG2': {\n",
    "        'modeljson': '/users/eprakash/projects/benchmarking/newdata/HepG2/models/deepseabeluga/momma_dragonn/examples/fasta_sequential_model/model_files/record_1_model_ppZZI_modelJson.json',\n",
    "        'modelweights': '/users/eprakash/projects/benchmarking/newdata/HepG2/models/deepseabeluga/momma_dragonn/examples/fasta_sequential_model/model_files/record_1_model_ppZZI_modelWeights.h5',\n",
    "        'valid_positive_set': '/users/eprakash/projects/benchmarking/newdata/HepG2/HepG2.summits.400bp.implanted.valid.bed.gz',\n",
    "        'valid_negative_set': '/users/eprakash/projects/benchmarking/newdata/HepG2/no_HepG2_universal_dnase.matched.valid.bed.gz'\n",
    "    },\n",
    "    'A549': {\n",
    "        'modeljson': '/users/eprakash/projects/benchmarking/newdata/A549/models/deepseabeluga/momma_dragonn/examples/fasta_sequential_model/model_files/record_1_model_ugaHs_modelJson.json',\n",
    "        'modelweights': '/users/eprakash/projects/benchmarking/newdata/A549/models/deepseabeluga/momma_dragonn/examples/fasta_sequential_model/model_files/record_1_model_ugaHs_modelWeights.h5',\n",
    "        'valid_positive_set': '/users/eprakash/projects/benchmarking/newdata/A549/A549.summits.400bp.implanted.train.bed.gz',\n",
    "        'valid_negative_set': '/users/eprakash/projects/benchmarking/newdata/A549/no_A549_universal_dnase.matched.valid.bed.gz'\n",
    "    },\n",
    "    'H1ESC': {\n",
    "        'modeljson': '/users/eprakash/projects/benchmarking/newdata/H1ESC/models/deepseabeluga/momma_dragonn/examples/fasta_sequential_model/model_files/record_1_model_rjU3H_modelJson.json',\n",
    "        'modelweights': '/users/eprakash/projects/benchmarking/newdata/H1ESC/models/deepseabeluga/momma_dragonn/examples/fasta_sequential_model/model_files/record_1_model_rjU3H_modelWeights.h5',\n",
    "        'valid_positive_set': '/users/eprakash/projects/benchmarking/newdata/H1ESC/H1ESC.summits.400bp.implanted.valid.bed.gz',\n",
    "        'valid_negative_set': '/users/eprakash/projects/benchmarking/newdata/H1ESC/no_H1ESC_universal_dnase.matched.valid.bed.gz'\n",
    "    },\n",
    "    'K562': {\n",
    "        'modeljson': '/users/eprakash/git/momma_dragonn/examples/fasta_sequential_model/model_files/oldmodels/record_4_model_4W8mu_modelJson.json',\n",
    "        'modelweights': '/users/eprakash/git/momma_dragonn/examples/fasta_sequential_model/model_files/oldmodels/record_4_model_4W8mu_modelWeights.h5',\n",
    "        'valid_positive_set': '/users/eprakash/projects/benchmarking/newdata/deepsea_K562/K562.pos.summits.valid.implanted.bed.gz',\n",
    "        'valid_negative_set': '/users/eprakash/projects/benchmarking/newdata/deepsea_K562/K562.neg.summits.valid.implanted.bed.gz'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import gzip\n",
    "import tensorflow as tf\n",
    "import deeplift.dinuc_shuffle\n",
    "\n",
    "\n",
    "def load_keras_model(modeljson, modelweights):\n",
    "    model = keras.models.model_from_json(open(modeljson).read())\n",
    "    model.load_weights(modelweights)\n",
    "    return model\n",
    "\n",
    "    \n",
    "def onehot_encode(seqs):\n",
    "    ltr = {'A': [1,0,0,0], 'C': [0,1,0,0], 'G': [0,0,1,0], 'T': [0,0,0,1], 'N': [0,0,0,0]}\n",
    "    return np.array([[ltr[x] for x in seq.upper()] for seq in seqs])\n",
    "\n",
    "\n",
    "def load_seqs_and_onehot(sequences_file):\n",
    "    seqids = []\n",
    "    seqs = []\n",
    "    for line in gzip.open(sequences_file):\n",
    "        seqid, seq = line.decode(\"utf-8\").rstrip().split(\"\\t\")\n",
    "        seqids.append(seqid)\n",
    "        seqs.append(seq)\n",
    "    onehotseqs = onehot_encode(seqs)\n",
    "    return seqids, seqs, onehotseqs\n",
    "\n",
    "\n",
    "def empty_ism_buffer(results_arr,\n",
    "                     input_data_onehot,\n",
    "                     perturbed_inputs_preds,\n",
    "                     perturbed_inputs_info):\n",
    "    for perturbed_input_pred,perturbed_input_info\\\n",
    "        in zip(perturbed_inputs_preds, perturbed_inputs_info):\n",
    "        example_idx = perturbed_input_info[0]\n",
    "        if (perturbed_input_info[1]==\"original\"):\n",
    "            results_arr[example_idx] +=\\\n",
    "                (perturbed_input_pred*input_data_onehot[example_idx])\n",
    "        else:\n",
    "            pos_idx,base_idx = perturbed_input_info[1]\n",
    "            results_arr[example_idx,pos_idx,base_idx] = perturbed_input_pred\n",
    "\n",
    "            \n",
    "def make_ism_func(pred_func,\n",
    "                  flank_around_middle_to_perturb,\n",
    "                  batch_size=200):\n",
    "    def ism_func(input_onehot, progress_update=1000, **kwargs):\n",
    "        input_data_onehot=input_onehot\n",
    "        \n",
    "        results_arr = np.zeros_like(input_data_onehot).astype(\"float64\")\n",
    "        \n",
    "        perturbed_inputs_info = []\n",
    "        perturbed_onehot_seqs = []\n",
    "        perturbed_inputs_preds = []\n",
    "        num_done = 0\n",
    "        for i,onehot_seq in enumerate(input_data_onehot):\n",
    "            perturbed_onehot_seqs.append(onehot_seq)\n",
    "            perturbed_inputs_info.append((i,\"original\"))\n",
    "            for pos in range(int(len(onehot_seq)/2)-flank_around_middle_to_perturb,\n",
    "                             int(len(onehot_seq)/2)+flank_around_middle_to_perturb):\n",
    "                for base_idx in range(4):\n",
    "                    if onehot_seq[pos,base_idx]==0:\n",
    "                        assert len(onehot_seq.shape)==2\n",
    "                        new_onehot = np.zeros_like(onehot_seq) + onehot_seq\n",
    "                        new_onehot[pos,:] = 0\n",
    "                        new_onehot[pos,base_idx] = 1\n",
    "                        perturbed_onehot_seqs.append(new_onehot)\n",
    "                        perturbed_inputs_info.append((i,(pos,base_idx)))\n",
    "                        num_done += 1\n",
    "                        if ((progress_update is not None)\n",
    "                            and num_done%progress_update==0):\n",
    "                            print(\"Done\",num_done)\n",
    "                        if (len(perturbed_inputs_info)>=batch_size):\n",
    "                            empty_ism_buffer(\n",
    "                                 results_arr=results_arr,\n",
    "                                 input_data_onehot=input_data_onehot,\n",
    "                                 perturbed_inputs_preds=\n",
    "                                  pred_func([perturbed_onehot_seqs]),\n",
    "                                 perturbed_inputs_info=perturbed_inputs_info)\n",
    "                            perturbed_inputs_info = []\n",
    "                            perturbed_onehot_seqs = []\n",
    "        if (len(perturbed_inputs_info)>0):\n",
    "            empty_ism_buffer(\n",
    "                 results_arr=results_arr,\n",
    "                 input_data_onehot=input_data_onehot,\n",
    "                 perturbed_inputs_preds=\n",
    "                  pred_func([perturbed_onehot_seqs]),\n",
    "                 perturbed_inputs_info=perturbed_inputs_info)\n",
    "        perturbed_inputs_info = []\n",
    "        perturbed_onehot_seqs = []\n",
    "        results_arr = results_arr - np.mean(results_arr,axis=-1)[:,:,None]\n",
    "        return input_data_onehot*results_arr\n",
    "    return ism_func\n",
    "\n",
    "\n",
    "def get_project_onto_bases_func(func):\n",
    "    def project_onto_bases(input_data_list, **kwargs):\n",
    "        assert len(input_data_list)==1\n",
    "        to_return = func(input_data_list=input_data_list, **kwargs)\n",
    "        return input_data_list[0]*np.sum(to_return,axis=-1)[:,:,None]\n",
    "    return project_onto_bases\n",
    "\n",
    "\n",
    "def get_grad_func(deeplift_model):\n",
    "    grad = tf.gradients(\n",
    "        ys=deeplift_genomicsdefault_model.get_layers()[-2].get_activation_vars(),\n",
    "        xs=deeplift_genomicsdefault_model.get_layers()[0].get_activation_vars())[0]\n",
    "    unbatched_grad_func = deeplift.util.compile_func(\n",
    "        inputs=[deeplift_genomicsdefault_model.get_layers()[0].get_activation_vars()],\n",
    "        outputs=grad)\n",
    "    #the grad_func needs to be in a deeplift-compatible API\n",
    "    def grad_func(input_data_list, input_references_list, task_idx, **kwargs):\n",
    "        assert len(input_data_list)==1\n",
    "        to_return = np.array(deeplift.util.run_function_in_batches(\n",
    "                        unbatched_grad_func,\n",
    "                        input_data_list=input_data_list,\n",
    "                        **kwargs))\n",
    "        return to_return\n",
    "    return grad_func\n",
    "\n",
    "\n",
    "def get_grad_times_inp_func(grad_func):\n",
    "    def grad_times_inp_func(input_onehot, **kwargs):\n",
    "        grads = grad_func(input_data_list=[input_onehot], **kwargs)\n",
    "        return grads*input_data_list[0]\n",
    "    return grad_times_inp_func\n",
    "\n",
    "#take a scoring func in the deeplift api and distill it\n",
    "# to essentials, when there is a fixed reference\n",
    "def distill_deepliftapi_withfixedref(deepliftapifunc, fixedref):\n",
    "    def distilled_func(input_onehot, **kwargs):\n",
    "        scores = deepliftapifunc(input_data_list=[input_onehot],\n",
    "                                 input_references_list=[fixedref],\n",
    "                                 task_idx=0, **kwargs)\n",
    "        return scores\n",
    "    return distilled_func\n",
    "\n",
    "\n",
    "#take a shuffref scoring function in the deeplift api and distill\n",
    "# it to essentials\n",
    "def distill_deepliftapi_multiref(deepliftapifunc, numrefs):\n",
    "    def distilled_func(input_onehot, **kwargs):\n",
    "        scores = deepliftapifunc(input_data_sequences=input_onehot,\n",
    "                                 num_refs_per_seq=numrefs,\n",
    "                                 task_idx=0,\n",
    "                                 seed=1, **kwargs)\n",
    "        return scores\n",
    "    return distilled_func\n",
    "    \n",
    "\n",
    "def get_scores(deeplift_genomicsdefault_model,\n",
    "               deeplift_rescale_model,\n",
    "               pred_func, input_onehot):\n",
    "    \n",
    "    assert len(input_onehot.shape)==3\n",
    "    zeroref = np.zeros((1,input_onehot.shape[1], input_onehot.shape[2]))\n",
    "    gcref = np.mean(input_onehot, axis=(0,1))[None,None,:]\n",
    "    \n",
    "    grad_func = get_grad_func(deeplift_model=deeplift_genomicsdefault_model)\n",
    "    grad_times_inp_func = get_grad_times_inp_func(grad_func=grad_func)\n",
    "    \n",
    "    intgrad10_func = get_project_onto_bases_func(\n",
    "                        deeplift.util.get_integrated_gradients_function(\n",
    "                        gradient_computation_function=grad_func, \n",
    "                        num_intervals=10))\n",
    "    intgrad10_zeroref_func = distill_deepliftapi_withfixedref(\n",
    "                                deepliftapifunc=intgrad10_func,\n",
    "                                fixedref=zeroref)\n",
    "    intgrad10_gcref_func = distill_deepliftapi_withfixedref(\n",
    "                                deepliftapifunc=intgrad10_func,\n",
    "                                fixedref=gcref)\n",
    "    \n",
    "    intgrad20_func = get_project_onto_bases_func(\n",
    "                        deeplift.util.get_integrated_gradients_function(\n",
    "                        gradient_computation_function=grad_func, \n",
    "                        num_intervals=20))\n",
    "    intgrad20_zeroref_func = distill_deepliftapi_withfixedref(\n",
    "                                deepliftapifunc=intgrad20_func,\n",
    "                                fixedref=zeroref)\n",
    "    intgrad20_gcref_func = distill_deepliftapi_withfixedref(\n",
    "                                deepliftapifunc=intgrad20_func,\n",
    "                                fixedref=gcref)\n",
    "    \n",
    "    ism_func = make_ism_func(pred_func=pred_func,\n",
    "                             flank_around_middle_to_perturb=200,\n",
    "                             batch_size=200)\n",
    "    \n",
    "    dldefault_func = get_project_onto_bases_func(\n",
    "        deeplift_genomicsdefault_model.get_target_contribs_func(find_scores_layer_idx=0))\n",
    "    \n",
    "    dlrescale_func = get_project_onto_bases_func(\n",
    "        deeplift_rescale_model.get_target_contribs_func(find_scores_layer_idx=0))\n",
    "    dlrescale_zeroref_func = distill_deepliftapi_withfixedref(\n",
    "                                deepliftapifunc=dlrescale_func,\n",
    "                                fixedref=zeroref)\n",
    "    dlrescale_gcref_func = distill_deepliftapi_withfixedref(\n",
    "                                deepliftapifunc=dlrescale_func,\n",
    "                                fixedref=gcref)\n",
    "    \n",
    "    dldefault_dinucshuffref10_func = distill_deepliftapi_multiref(\n",
    "        deepliftapifunc=deeplift.util.get_shuffle_seq_ref_function(\n",
    "            score_computation_function=dldefault_func,\n",
    "            shuffle_func=deeplift.dinuc_shuffle.dinuc_shuffle),\n",
    "        numrefs=10)\n",
    "    dlrescale_dinucshuffref10_func = distill_deepliftapi_multiref(\n",
    "        deepliftapifunc=deeplift.util.get_shuffle_seq_ref_function(\n",
    "            score_computation_function=dlrescale_func,\n",
    "            shuffle_func=deeplift.dinuc_shuffle.dinuc_shuffle),\n",
    "        numrefs=10)\n",
    "    \n",
    "    intgrad10_dinucshuffref10_func = distill_deepliftapi_multiref(\n",
    "        deepliftapifunc=deeplift.util.get_shuffle_seq_ref_function(\n",
    "            score_computation_function=intgrad10_func,\n",
    "            shuffle_func=deeplift.dinuc_shuffle.dinuc_shuffle),\n",
    "        numrefs=10)\n",
    "    intgrad20_dinucshuffref10_func = distill_deepliftapi_multiref(\n",
    "        deepliftapifunc=deeplift.util.get_shuffle_seq_ref_function(\n",
    "            score_computation_function=intgrad20_func,\n",
    "            shuffle_func=deeplift.dinuc_shuffle.dinuc_shuffle),\n",
    "        numrefs=10)\n",
    "\n",
    "    methodname_to_scoringfunc = {\n",
    "        'ism': ism_func,\n",
    "        'gradtimesinp': grad_times_inp_func,\n",
    "        'intgrad10_zeroref': intgrad10_zeroref_func,\n",
    "        'intgrad10_gcref': intgrad10_gcref_func,\n",
    "        'intgrad20_zeroref': intgrad20_zeroref_func,\n",
    "        'intgrad20_gcref': intgrad20_gcref_func,\n",
    "        'dlrescale_zeroref': dlrescale_zeroref_func,\n",
    "        'dlrescale_gcref': dlrescale_gcref_func,\n",
    "        'dldefault_dinucshuffref10': dldefault_dinucshuffref10_func,\n",
    "        'dlrescale_dinucshuffref10': dlrescale_dinucshuffref10_func,\n",
    "        'intgrad10_dinucshuffref10': intgrad10_dinucshuffref10_func,\n",
    "        'intgrad20_dinucshuffref10': intgrad20_dinucshuffref10_func\n",
    "    }\n",
    "    \n",
    "    methodname_to_scores = {}\n",
    "    for methodname in sorted(methodname_to_scoringfunc.keys()):\n",
    "        print(\"On method\", methodname)\n",
    "        scoringfunc = methodname_to_scoringfunc[methodname]\n",
    "        methodname_to_scores[methodname] =\\\n",
    "            scoringfunc(input_onehot=input_onehot,\n",
    "                        batch_size=200,\n",
    "                        progress_update=1000)\n",
    "    \n",
    "    return methodname_to_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On cell type H1ESC\n",
      "nonlinear_mxts_mode is set to: DeepLIFT_GenomicsDefault\n",
      "For layer 1 the preceding linear layer is 0 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "For layer 3 the preceding linear layer is 2 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "For layer 7 the preceding linear layer is 6 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "For layer 9 the preceding linear layer is 8 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "For layer 13 the preceding linear layer is 12 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "For layer 15 the preceding linear layer is 14 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "For layer 18 the preceding linear layer is 17 of type Dense;\n",
      "In accordance with nonlinear_mxts_modeDeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to RevealCancel\n",
      "Heads-up: I assume sigmoid is the output layer, not an intermediate one; if it's an intermediate layer then please bug me and I will implement the grad func\n",
      "For layer 20 the preceding linear layer is 19 of type Dense;\n",
      "In accordance with nonlinear_mxts_modeDeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to RevealCancel\n",
      "nonlinear_mxts_mode is set to: Rescale\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "Heads-up: I assume sigmoid is the output layer, not an intermediate one; if it's an intermediate layer then please bug me and I will implement the grad func\n",
      "REMOVE ME\n",
      "Done 0\n",
      "Done 0\n",
      "avg prec 0.9992307692307694\n",
      "roc auc 0.9992\n",
      "Prediction on avg pos: 8.715177\n",
      "Prediction on avg neg: -8.094089\n",
      "Prediction on all zeros: [-6.4120007]\n",
      "Prediction on avg gc of pos: [-6.561149]\n",
      "Prediction on avg gc of neg: [-6.561149]\n",
      "On method dldefault_dinucshuffref10\n",
      "Done 0\n",
      "On method dlrescale_dinucshuffref10\n",
      "Done 0\n",
      "On method dlrescale_gcref\n",
      "Done 0\n",
      "On method dlrescale_zeroref\n",
      "Done 0\n",
      "On method gradtimesinp\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'input_data_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-3053798f54fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mdeeplift_rescale_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeeplift_rescale_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mpred_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         input_onehot=subset_pos_onehot)\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcelltype\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_scores.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-113-0a0044243467>\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(deeplift_genomicsdefault_model, deeplift_rescale_model, pred_func, input_onehot)\u001b[0m\n\u001b[1;32m    243\u001b[0m             scoringfunc(input_onehot=input_onehot,\n\u001b[1;32m    244\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                         progress_update=1000)\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethodname_to_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-113-0a0044243467>\u001b[0m in \u001b[0;36mgrad_times_inp_func\u001b[0;34m(input_onehot, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_grad_times_inp_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad_times_inp_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_onehot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_data_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_data_list' is not defined"
     ]
    }
   ],
   "source": [
    "import deeplift\n",
    "from deeplift.conversion import kerasapi_conversion as kc\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "import sys\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "celltypes = ['H1ESC']\n",
    "\n",
    "num_to_make_preds_on = 50\n",
    "\n",
    "for celltype in celltypes:\n",
    "    print(\"On cell type\",celltype)\n",
    "    sys.stdout.flush()\n",
    "    corefiles = celltype_to_corefiles[celltype]\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    deeplift_genomicsdefault_model =\\\n",
    "        kc.convert_model_from_saved_files(\n",
    "            json_file=corefiles['modeljson'],\n",
    "            h5_file=corefiles['modelweights'],\n",
    "            nonlinear_mxts_mode=deeplift.layers.NonlinearMxtsMode.DeepLIFT_GenomicsDefault) \n",
    "    deeplift_rescale_model =\\\n",
    "        kc.convert_model_from_saved_files(\n",
    "            json_file=corefiles['modeljson'],\n",
    "            h5_file=corefiles['modelweights'],\n",
    "            nonlinear_mxts_mode=deeplift.layers.NonlinearMxtsMode.Rescale) \n",
    "    pred_func = deeplift.util.compile_func(\n",
    "        inputs=[deeplift_rescale_model.get_layers()[0].get_activation_vars()],\n",
    "        outputs=deeplift_rescale_model.get_layers()[-2].get_activation_vars()[:,0])\n",
    "    \n",
    "    (pos_seqids, pos_seqs, pos_onehotseqs) = (\n",
    "        load_seqs_and_onehot(sequences_file=corefiles['valid_positive_set']))\n",
    "    (neg_seqids, neg_seqs, neg_onehotseqs) = (\n",
    "        load_seqs_and_onehot(sequences_file=corefiles['valid_negative_set']))\n",
    "    \n",
    "    pos_onehotseqs = pos_onehotseqs[:num_to_make_preds_on]\n",
    "    neg_onehotseqs = neg_onehotseqs[:num_to_make_preds_on]\n",
    "    print(\"REMOVE ME\")\n",
    "    \n",
    "    pos_preds = np.array(deeplift.util.run_function_in_batches(pred_func,\n",
    "                            input_data_list=[pos_onehotseqs],\n",
    "                            batch_size=200,\n",
    "                            progress_update=10000))\n",
    "    neg_preds = np.array(deeplift.util.run_function_in_batches(pred_func,\n",
    "                            input_data_list=[neg_onehotseqs],\n",
    "                            batch_size=200,\n",
    "                            progress_update=10000))\n",
    "    \n",
    "    y_true = [1 for x in pos_preds]+[0 for x in neg_preds]\n",
    "    y_score = list(pos_preds)+list(neg_preds)\n",
    "    \n",
    "    print(\"avg prec\", average_precision_score(y_true=y_true,\n",
    "                                              y_score=y_score))\n",
    "    sys.stdout.flush()\n",
    "    print(\"roc auc\", roc_auc_score(y_true=y_true, y_score=y_score))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    seqids_top_pred_positives = sorted(enumerate(zip(pos_seqids, pos_preds)),\n",
    "        key=lambda x: -x[1][1])[:num_to_make_preds_on]\n",
    "    open(celltype+\"_toppredpos.txt\",'w').write(\n",
    "        \"\\n\".join(x[1][0] for x in seqids_top_pred_positives))\n",
    "    \n",
    "    print(\"Prediction on avg pos:\", np.mean(pos_preds))\n",
    "    print(\"Prediction on avg neg:\", np.mean(neg_preds))\n",
    "    print(\"Prediction on all zeros:\", pred_func([np.zeros((1,400,4))]))\n",
    "    avgpos_gcref = np.mean(pos_onehotseqs, axis=0, keepdims=True)\n",
    "    print(\"Prediction on avg gc of pos:\", pred_func([avgpos_gcref]))\n",
    "    avgneg_gcref = np.mean(neg_onehotseqs, axis=0, keepdims=True)\n",
    "    print(\"Prediction on avg gc of neg:\", pred_func([avgneg_gcref]))\n",
    "    \n",
    "    toppredpos_indices = [x[0] for x in seqids_top_pred_positives]\n",
    "    subset_pos_onehot = pos_onehotseqs[toppredpos_indices]\n",
    "    \n",
    "    methodname_to_scores = get_scores(\n",
    "        deeplift_genomicsdefault_model=deeplift_genomicsdefault_model,\n",
    "        deeplift_rescale_model=deeplift_rescale_model,\n",
    "        pred_func=pred_func,\n",
    "        input_onehot=subset_pos_onehot)\n",
    "    \n",
    "    if (os.path.exists(celltype+\"_scores.h5\")):\n",
    "        os.remove(celltype+\"_scores.h5\")\n",
    "    outf = h5py.File(celltype+\"_scores.h5\")\n",
    "    for methodname in methodname_to_scores:\n",
    "        outf.create_dataset(methodname,\n",
    "                            data=methodname_to_scores[methodname])\n",
    "    outf.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
