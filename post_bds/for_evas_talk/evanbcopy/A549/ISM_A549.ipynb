{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "def load_sequences(seqfile):\n",
    "        seqs = OrderedDict()\n",
    "        fp = gzip.open(seqfile, \"rb\")\n",
    "        print(\"#Loading \" + seqfile + \" ...\")\n",
    "        expecting = \"label\"\n",
    "        label=''\n",
    "        for line in fp:\n",
    "                if expecting == \"label\":\n",
    "                        match = re.match(\">(.*)$\", line)\n",
    "                        if match:\n",
    "                                label = match.group(1)\n",
    "                                expecting = \"sequence\"\n",
    "                        else:\n",
    "                                print(\"Expecting LABEL but found (!!): \" + line)\n",
    "                                continue\n",
    "                else:\n",
    "                        match = re.match(\"(\\w+)$\", line)\n",
    "                        if match:\n",
    "                                sequence = match.group(1)\n",
    "                                seqs[label]=sequence\n",
    "                        else:\n",
    "                                print(\"Expecting SEQUENCE but found (!!): \" + line)\n",
    "                        expecting = \"label\"\n",
    "                        label=''\n",
    "        fp.close()\n",
    "        print(\"#Loaded \" + str(len(seqs.keys())) + \" sequences from \" + seqfile)\n",
    "        return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_motif_matches(motif_match_file, doprint=False):\n",
    "        \"\"\"\n",
    "        Loads a homer motif match file into an ordered dictionary with key as se\n",
    "quence name\n",
    "        and value as list of dictionaries each containing the keys - motif, sequ\n",
    "ence,\n",
    "        begin (0-indexed inclusive begin index of motif), end (0-indexed exclusi\n",
    "ve end index),\n",
    "        strand (+ or -), seqval. Each dictionary\n",
    "        represents one motif match on that sequence\n",
    "        \"\"\"\n",
    "        motif_matches = OrderedDict()\n",
    "        fp = open(motif_match_file, \"r\")\n",
    "        if doprint:\n",
    "                print(\"#Loading \" + motif_match_file + \" ...\")\n",
    "        numlines = 0\n",
    "        for line in fp:\n",
    "                match = re.match(\"((\\w|\\-)+)\\s+((\\w|\\:|\\-)+)\\s+(\\d+)\\s+(\\d+)\\s+(\\+|\\-)\\s+.+\\s+(\\w+)$\", line)\n",
    "                if match:\n",
    "                        numlines = numlines + 1\n",
    "                        motif = match.group(1)\n",
    "                        sequence = match.group(3)\n",
    "                        begin = int(match.group(5))\n",
    "                        end = int(match.group(6))\n",
    "                        strand = match.group(7)\n",
    "                        seqval = match.group(8)\n",
    "                        entry = dict()\n",
    "                        entry['motif'] = motif\n",
    "                        entry['sequence'] = sequence\n",
    "                        entry['begin'] = begin-1 # Homer motif match file is 1 indexed, convert to 0\n",
    "                        entry['end'] = end # Homer motif match file is 1 indexed AND inclusive, convert to 0 and exclusive\n",
    "                        entry['strand'] = strand\n",
    "                        entry['seqval'] = seqval\n",
    "                        if sequence not in motif_matches:\n",
    "                                motif_matches[sequence] = list()\n",
    "                        motif_matches[sequence].append(entry)\n",
    "        fp.close()\n",
    "        if doprint:\n",
    "                print(\"#Loaded \" + str(numlines) + \" motif matches in \" + str(len(motif_matches.keys())) + \" sequences\")\n",
    "        return motif_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rename(label):\n",
    "    match=re.match('.*_(chr.*)$',label)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_sequences_from_bedfile(seqfile):\n",
    "    seqs = OrderedDict()\n",
    "    fp = gzip.open(seqfile, \"rb\")\n",
    "    print(\"#Loading \" + seqfile + \" ...\")\n",
    "    for line in fp:\n",
    "        (label, sequence)=line.split()\n",
    "        seqs[label]=sequence\n",
    "    fp.close()\n",
    "    print(\"#Loaded \" + str(len(seqs.keys())) + \" sequences from \" + seqfile)\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_value(label):\n",
    "    value = -1\n",
    "    match = re.match(\"((dinuc_shuff_|dinuc_shuffled_).+)$\", label)\n",
    "    if match:            \n",
    "        chrom = match.group(1)\n",
    "        if match.group(2) == 'dinuc_shuff_':\n",
    "            value = 0\n",
    "        else:\n",
    "            value = 1\n",
    "    return value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def get_random_set(seqdict, num, sort=True):\n",
    "    newlist=seqdict.items()\n",
    "    if sort:\n",
    "        newlist = [newlist[i] for i in sorted(random.sample(range(len(newlist)), num))]\n",
    "    else:\n",
    "        newlist = [newlist[i] for i in random.sample(range(len(newlist)), num)]\n",
    "    return dict(newlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_labels_not_in_motif_matches(sequences, motif_matches):\n",
    "    positive_keys=[]\n",
    "    for key in motif_matches.keys():\n",
    "        positive_keys.append(key)\n",
    "    positive_keys_set = set(positive_keys)\n",
    "    #print(\"Positive Keys Set\")\n",
    "    #print(positive_keys_set)\n",
    "    #print(\"Sequence keys\")\n",
    "    #print(sequences.keys())\n",
    "    new_seqs = OrderedDict()\n",
    "    for seq in sequences.keys():\n",
    "        if rename(seq) in positive_keys_set:\n",
    "            new_seqs[seq] = sequences[seq]\n",
    "    return new_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loading /users/eprakash/projects/benchmarking/newdata/A549/A549.summits.400bp.implanted.5Ksubsample.bed.gz ...\n",
      "#Loaded 5000 sequences from /users/eprakash/projects/benchmarking/newdata/A549/A549.summits.400bp.implanted.5Ksubsample.bed.gz\n",
      "#Loading /users/eprakash/projects/benchmarking/newdata/A549/A549.summits.400bp.implanted.5Ksubsample.bed.gz ...\n",
      "#Loaded 5000 sequences from /users/eprakash/projects/benchmarking/newdata/A549/A549.summits.400bp.implanted.5Ksubsample.bed.gz\n",
      "Got 5000 positive sequences\n",
      "Sequences length:  5000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_filename_positive = \"/users/eprakash/projects/benchmarking/newdata/A549/A549.summits.400bp.implanted.5Ksubsample.bed.gz\"\n",
    "#data_filename_negative = \"/users/eprakash/projects/benchmarking/newdata/GM12878/400bp/universal_dnase.matched.GM12878.summits.400bp.hg38.implanted.bed.gz\"\n",
    "positives=load_sequences_from_bedfile(data_filename_positive)\n",
    "labeled_sequences = load_sequences_from_bedfile(data_filename_positive)\n",
    "#print(\"Initially got %d positive sequences\" % len(labeled_sequences))\n",
    "#motif_matches=load_motif_matches('/users/eprakash/projects/benchmarking/newdata/GM12878/400bp/GM12878.motif.matches.txt', True)\n",
    "#labeled_sequences = remove_labels_not_in_motif_matches(labeled_sequences, motif_matches)\n",
    "#del labeled_sequences['chr1:203649072-203650072']\n",
    "print(\"Got %d positive sequences\" % len(labeled_sequences))\n",
    "positive_labels = labeled_sequences.keys()\n",
    "\n",
    "#Temporarily not including negative seqs\n",
    "#neg_seqs = load_sequences_from_bedfile(data_filename_negative)\n",
    "\n",
    "#del neg_seqs['chr1:203649072-203650072']\n",
    "#neg_seqs = get_random_set(neg_seqs, 200000)\n",
    "\n",
    "#print(\"Got %d negative sequences\" % len(neg_seqs))\n",
    "#negative_labels = neg_seqs.keys()\n",
    "#print(\"Number of labels common to both sets of sequences is %d \" % len(set(positive_labels).intersection(set(negative_labels))))\n",
    "#labeled_sequences.update(neg_seqs)\n",
    "#labeled_sequences=get_random_set(labeled_sequences, 419730, sort=False)\n",
    "#labeled_sequences=get_random_set(labeled_sequences, 68407, sort=False)\n",
    "\n",
    "labels = labeled_sequences.keys()\n",
    "sequences=labeled_sequences.values()\n",
    "#values = np.array([get_value(label) for label in labels])\n",
    "#check_negatives = np.nonzero(values == -1)[0]\n",
    "#assert (len(check_negatives) == 0)\n",
    "#print(\"Labels length: \", len(labels))\n",
    "print(\"Sequences length: \", len(sequences))\n",
    "#print(\"Values length: \", len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "removed=[]\n",
    "chars=['R','Y','S','W','K','M','B','D','H','V','N']\n",
    "print(len(sequences))\n",
    "for seq in sequences:\n",
    "    if any((c in chars) for c in seq):\n",
    "        removed.append(seq)\n",
    "        sequences.remove(seq)\n",
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "for i in removed:\n",
    "    key=labeled_sequences.keys()[labeled_sequences.values().index(i)]\n",
    "    print(key)\n",
    "    del labeled_sequences[key]\n",
    "    labels.remove(key)\n",
    "print (len(labels))\n",
    "print(len(labeled_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.OrderedDict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(labeled_sequences))\n",
    "with open(\"/users/eprakash/projects/benchmarking/newdata/A549/models/deepseabeluga/results/ISM_deepseabeluga_A549_positive.labels.txt\", \"w\") as ff:\n",
    "    for ss in labeled_sequences.keys():\n",
    "        ff.write(str(ss) +\"\\n\")\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#this is set up for 1d convolutions where examples\n",
    "#have dimensions (len, num_channels)\n",
    "#the channel axis is the axis for one-hot encoding.\n",
    "def one_hot_encode_along_channel_axis(sequence):\n",
    "    to_return = np.zeros((len(sequence),4), dtype=np.int8)\n",
    "    seq_to_one_hot_fill_in_array(zeros_array=to_return,\n",
    "                                 sequence=sequence, one_hot_axis=1)\n",
    "    return to_return\n",
    "\n",
    "def seq_to_one_hot_fill_in_array(zeros_array, sequence, one_hot_axis):\n",
    "    assert one_hot_axis==0 or one_hot_axis==1\n",
    "    if (one_hot_axis==0):\n",
    "        assert zeros_array.shape[1] == len(sequence)\n",
    "    elif (one_hot_axis==1): \n",
    "        assert zeros_array.shape[0] == len(sequence)\n",
    "    #will mutate zeros_array\n",
    "    for (i,char) in enumerate(sequence):\n",
    "        if (char==\"A\" or char==\"a\"):\n",
    "            char_idx = 0\n",
    "        elif (char==\"C\" or char==\"c\"):\n",
    "            char_idx = 1\n",
    "        elif (char==\"G\" or char==\"g\"):\n",
    "            char_idx = 2\n",
    "        elif (char==\"T\" or char==\"t\"):\n",
    "            char_idx = 3\n",
    "        elif (char==\"N\" or char==\"n\"):\n",
    "            continue #leave that pos as all 0's\n",
    "        else:\n",
    "            raise RuntimeError(\"Unsupported character: \"+str(char))\n",
    "        if (one_hot_axis==0):\n",
    "            zeros_array[char_idx,i] = 1\n",
    "        elif (one_hot_axis==1):\n",
    "            zeros_array[i,char_idx] = 1\n",
    "#sequences = sequences[-5000:]            \n",
    "onehot_data = np.array([one_hot_encode_along_channel_axis(seq) for seq in sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 400, 4)\n"
     ]
    }
   ],
   "source": [
    "print(onehot_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import deeplift\n",
    "from deeplift.conversion import kerasapi_conversion as kc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonlinear_mxts_mode is set to: DeepLIFT_GenomicsDefault\n",
      "For layer 1 the preceding linear layer is 0 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "For layer 3 the preceding linear layer is 2 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "For layer 7 the preceding linear layer is 6 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "For layer 9 the preceding linear layer is 8 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "For layer 13 the preceding linear layer is 12 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "For layer 15 the preceding linear layer is 14 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "For layer 18 the preceding linear layer is 17 of type Dense;\n",
      "In accordance with nonlinear_mxts_modeDeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to RevealCancel\n",
      "Heads-up: I assume sigmoid is the output layer, not an intermediate one; if it's an intermediate layer then please bug me and I will implement the grad func\n",
      "For layer 20 the preceding linear layer is 19 of type Dense;\n",
      "In accordance with nonlinear_mxts_modeDeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to RevealCancel\n",
      "nonlinear_mxts_mode is set to: Rescale\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "Heads-up: I assume sigmoid is the output layer, not an intermediate one; if it's an intermediate layer then please bug me and I will implement the grad func\n"
     ]
    }
   ],
   "source": [
    "#model_id = \"record_4_model_4W8mu\"\n",
    "model_json = \"/users/eprakash/projects/benchmarking/newdata/A549/models/deepseabeluga/momma_dragonn/examples/fasta_sequential_model/model_files/record_1_model_SkPDS_modelJson.json\"\n",
    "model_weights = \"/users/eprakash/projects/benchmarking/newdata/A549/models/deepseabeluga/momma_dragonn/examples/fasta_sequential_model/model_files/record_1_model_SkPDS_modelWeights.h5\"\n",
    "#model_json = \"model_files/model_UqOJX_modelJson.json\"\n",
    "#model_weights = \"model_files/model_UqOJX_modelWeights.h5\"\n",
    "deeplift_genomicsdefault_model =\\\n",
    "    kc.convert_model_from_saved_files(\n",
    "        json_file=model_json,\n",
    "        h5_file=model_weights,\n",
    "        nonlinear_mxts_mode=deeplift.layers.NonlinearMxtsMode.DeepLIFT_GenomicsDefault) \n",
    "deeplift_rescale_model =\\\n",
    "    kc.convert_model_from_saved_files(\n",
    "        json_file=model_json,\n",
    "        h5_file=model_weights,\n",
    "        nonlinear_mxts_mode=deeplift.layers.NonlinearMxtsMode.Rescale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_wrapper(func):\n",
    "    def wrapped_func(input_data_list, **kwargs):\n",
    "        if (isinstance(input_data_list, list)):\n",
    "            remove_list_on_return=False\n",
    "        else:\n",
    "            remove_list_on_return=True\n",
    "            input_data_list = [input_data_list]\n",
    "        to_return = func(input_data_list=input_data_list,\n",
    "                         **kwargs)\n",
    "        return to_return\n",
    "    return wrapped_func\n",
    "\n",
    "def empty_ism_buffer(results_arr,\n",
    "                     input_data_onehot,\n",
    "                     perturbed_inputs_preds,\n",
    "                     perturbed_inputs_info):\n",
    "    for perturbed_input_pred,perturbed_input_info\\\n",
    "        in zip(perturbed_inputs_preds, perturbed_inputs_info):\n",
    "        example_idx = perturbed_input_info[0]\n",
    "        if (perturbed_input_info[1]==\"original\"):\n",
    "            results_arr[example_idx] +=\\\n",
    "                (perturbed_input_pred*input_data_onehot[example_idx])\n",
    "        else:\n",
    "            pos_idx,base_idx = perturbed_input_info[1]\n",
    "            results_arr[example_idx,pos_idx,base_idx] = perturbed_input_pred\n",
    "\n",
    "def make_ism_func(prediction_func,\n",
    "                  flank_around_middle_to_perturb,\n",
    "                  batch_size=200):\n",
    "    @list_wrapper\n",
    "    def ism_func(input_data_list, progress_update=10000, **kwargs):\n",
    "        assert len(input_data_list)==1\n",
    "        input_data_onehot=input_data_list[0]\n",
    "        \n",
    "        results_arr = np.zeros_like(input_data_onehot).astype(\"float64\")\n",
    "        \n",
    "        perturbed_inputs_info = []\n",
    "        perturbed_onehot_seqs = []\n",
    "        perturbed_inputs_preds = []\n",
    "        num_done = 0\n",
    "        for i,onehot_seq in enumerate(input_data_onehot):\n",
    "            perturbed_onehot_seqs.append(onehot_seq)\n",
    "            perturbed_inputs_info.append((i,\"original\"))\n",
    "            for pos in range(int(len(onehot_seq)/2)-flank_around_middle_to_perturb,\n",
    "                             int(len(onehot_seq)/2)+flank_around_middle_to_perturb):\n",
    "                for base_idx in range(4):\n",
    "                    if onehot_seq[pos,base_idx]==0:\n",
    "                        assert len(onehot_seq.shape)==2\n",
    "                        new_onehot = np.zeros_like(onehot_seq) + onehot_seq\n",
    "                        new_onehot[pos,:] = 0\n",
    "                        new_onehot[pos,base_idx] = 1\n",
    "                        perturbed_onehot_seqs.append(new_onehot)\n",
    "                        perturbed_inputs_info.append((i,(pos,base_idx)))\n",
    "                        num_done += 1\n",
    "                        if ((progress_update is not None)\n",
    "                            and num_done%progress_update==0):\n",
    "                            print(\"Done\",num_done)\n",
    "                        if (len(perturbed_inputs_info)>=batch_size):\n",
    "                            empty_ism_buffer(\n",
    "                                 results_arr=results_arr,\n",
    "                                 input_data_onehot=input_data_onehot,\n",
    "                                 perturbed_inputs_preds=\n",
    "                                  prediction_func([perturbed_onehot_seqs]),\n",
    "                                 perturbed_inputs_info=perturbed_inputs_info)\n",
    "                            perturbed_inputs_info = []\n",
    "                            perturbed_onehot_seqs = []\n",
    "        if (len(perturbed_inputs_info)>0):\n",
    "            empty_ism_buffer(\n",
    "                 results_arr=results_arr,\n",
    "                 input_data_onehot=input_data_onehot,\n",
    "                 perturbed_inputs_preds=\n",
    "                  prediction_func([perturbed_onehot_seqs]),\n",
    "                 perturbed_inputs_info=perturbed_inputs_info)\n",
    "        perturbed_inputs_info = []\n",
    "        perturbed_onehot_seqs = []\n",
    "        results_arr = results_arr - np.mean(results_arr,axis=-1)[:,:,None]\n",
    "        return input_data_onehot*results_arr\n",
    "    return ism_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_func = deeplift.util.compile_func(\n",
    "    inputs=[deeplift_rescale_model.get_layers()[0].get_activation_vars()],\n",
    "    outputs=deeplift_rescale_model.get_layers()[-2].get_activation_vars()[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ism_func = make_ism_func(prediction_func=pred_func,\n",
    "                         flank_around_middle_to_perturb=200,\n",
    "                         batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 10000\n",
      "Done 20000\n",
      "Done 30000\n",
      "Done 40000\n",
      "Done 50000\n",
      "Done 60000\n",
      "Done 70000\n",
      "Done 80000\n",
      "Done 90000\n",
      "Done 100000\n",
      "Done 110000\n",
      "Done 120000\n",
      "Done 130000\n",
      "Done 140000\n",
      "Done 150000\n",
      "Done 160000\n",
      "Done 170000\n",
      "Done 180000\n",
      "Done 190000\n",
      "Done 200000\n",
      "Done 210000\n",
      "Done 220000\n",
      "Done 230000\n",
      "Done 240000\n",
      "Done 250000\n",
      "Done 260000\n",
      "Done 270000\n",
      "Done 280000\n",
      "Done 290000\n",
      "Done 300000\n",
      "Done 310000\n",
      "Done 320000\n",
      "Done 330000\n",
      "Done 340000\n",
      "Done 350000\n",
      "Done 360000\n",
      "Done 370000\n",
      "Done 380000\n",
      "Done 390000\n",
      "Done 400000\n",
      "Done 410000\n",
      "Done 420000\n",
      "Done 430000\n",
      "Done 440000\n",
      "Done 450000\n",
      "Done 460000\n",
      "Done 470000\n",
      "Done 480000\n",
      "Done 490000\n",
      "Done 500000\n",
      "Done 510000\n",
      "Done 520000\n",
      "Done 530000\n",
      "Done 540000\n",
      "Done 550000\n",
      "Done 560000\n",
      "Done 570000\n",
      "Done 580000\n",
      "Done 590000\n",
      "Done 600000\n",
      "Done 610000\n",
      "Done 620000\n",
      "Done 630000\n",
      "Done 640000\n",
      "Done 650000\n",
      "Done 660000\n",
      "Done 670000\n",
      "Done 680000\n",
      "Done 690000\n",
      "Done 700000\n",
      "Done 710000\n",
      "Done 720000\n",
      "Done 730000\n",
      "Done 740000\n",
      "Done 750000\n",
      "Done 760000\n",
      "Done 770000\n",
      "Done 780000\n",
      "Done 790000\n",
      "Done 800000\n",
      "Done 810000\n",
      "Done 820000\n",
      "Done 830000\n",
      "Done 840000\n",
      "Done 850000\n",
      "Done 860000\n",
      "Done 870000\n",
      "Done 880000\n",
      "Done 890000\n",
      "Done 900000\n",
      "Done 910000\n",
      "Done 920000\n",
      "Done 930000\n",
      "Done 940000\n",
      "Done 950000\n",
      "Done 960000\n",
      "Done 970000\n",
      "Done 980000\n",
      "Done 990000\n",
      "Done 1000000\n",
      "Done 1010000\n",
      "Done 1020000\n",
      "Done 1030000\n",
      "Done 1040000\n",
      "Done 1050000\n",
      "Done 1060000\n",
      "Done 1070000\n",
      "Done 1080000\n",
      "Done 1090000\n",
      "Done 1100000\n",
      "Done 1110000\n",
      "Done 1120000\n",
      "Done 1130000\n",
      "Done 1140000\n",
      "Done 1150000\n",
      "Done 1160000\n",
      "Done 1170000\n",
      "Done 1180000\n",
      "Done 1190000\n",
      "Done 1200000\n",
      "Done 1210000\n",
      "Done 1220000\n",
      "Done 1230000\n",
      "Done 1240000\n",
      "Done 1250000\n",
      "Done 1260000\n",
      "Done 1270000\n",
      "Done 1280000\n",
      "Done 1290000\n",
      "Done 1300000\n",
      "Done 1310000\n",
      "Done 1320000\n",
      "Done 1330000\n",
      "Done 1340000\n",
      "Done 1350000\n",
      "Done 1360000\n",
      "Done 1370000\n",
      "Done 1380000\n",
      "Done 1390000\n",
      "Done 1400000\n",
      "Done 1410000\n",
      "Done 1420000\n",
      "Done 1430000\n",
      "Done 1440000\n",
      "Done 1450000\n",
      "Done 1460000\n",
      "Done 1470000\n",
      "Done 1480000\n",
      "Done 1490000\n",
      "Done 1500000\n",
      "Done 1510000\n",
      "Done 1520000\n",
      "Done 1530000\n",
      "Done 1540000\n",
      "Done 1550000\n",
      "Done 1560000\n",
      "Done 1570000\n",
      "Done 1580000\n",
      "Done 1590000\n",
      "Done 1600000\n",
      "Done 1610000\n",
      "Done 1620000\n",
      "Done 1630000\n",
      "Done 1640000\n",
      "Done 1650000\n",
      "Done 1660000\n",
      "Done 1670000\n",
      "Done 1680000\n",
      "Done 1690000\n",
      "Done 1700000\n",
      "Done 1710000\n",
      "Done 1720000\n",
      "Done 1730000\n",
      "Done 1740000\n",
      "Done 1750000\n",
      "Done 1760000\n",
      "Done 1770000\n",
      "Done 1780000\n",
      "Done 1790000\n",
      "Done 1800000\n",
      "Done 1810000\n",
      "Done 1820000\n",
      "Done 1830000\n",
      "Done 1840000\n",
      "Done 1850000\n",
      "Done 1860000\n",
      "Done 1870000\n",
      "Done 1880000\n",
      "Done 1890000\n",
      "Done 1900000\n",
      "Done 1910000\n",
      "Done 1920000\n",
      "Done 1930000\n",
      "Done 1940000\n",
      "Done 1950000\n",
      "Done 1960000\n",
      "Done 1970000\n",
      "Done 1980000\n",
      "Done 1990000\n",
      "Done 2000000\n",
      "Done 2010000\n",
      "Done 2020000\n",
      "Done 2030000\n",
      "Done 2040000\n",
      "Done 2050000\n",
      "Done 2060000\n",
      "Done 2070000\n",
      "Done 2080000\n",
      "Done 2090000\n",
      "Done 2100000\n",
      "Done 2110000\n",
      "Done 2120000\n",
      "Done 2130000\n",
      "Done 2140000\n",
      "Done 2150000\n",
      "Done 2160000\n",
      "Done 2170000\n",
      "Done 2180000\n",
      "Done 2190000\n",
      "Done 2200000\n",
      "Done 2210000\n",
      "Done 2220000\n",
      "Done 2230000\n",
      "Done 2240000\n",
      "Done 2250000\n",
      "Done 2260000\n",
      "Done 2270000\n",
      "Done 2280000\n",
      "Done 2290000\n",
      "Done 2300000\n",
      "Done 2310000\n",
      "Done 2320000\n",
      "Done 2330000\n",
      "Done 2340000\n",
      "Done 2350000\n",
      "Done 2360000\n",
      "Done 2370000\n",
      "Done 2380000\n",
      "Done 2390000\n",
      "Done 2400000\n",
      "Done 2410000\n",
      "Done 2420000\n",
      "Done 2430000\n",
      "Done 2440000\n",
      "Done 2450000\n",
      "Done 2460000\n",
      "Done 2470000\n",
      "Done 2480000\n",
      "Done 2490000\n",
      "Done 2500000\n",
      "Done 2510000\n",
      "Done 2520000\n",
      "Done 2530000\n",
      "Done 2540000\n",
      "Done 2550000\n",
      "Done 2560000\n",
      "Done 2570000\n",
      "Done 2580000\n",
      "Done 2590000\n",
      "Done 2600000\n",
      "Done 2610000\n",
      "Done 2620000\n",
      "Done 2630000\n",
      "Done 2640000\n",
      "Done 2650000\n",
      "Done 2660000\n",
      "Done 2670000\n",
      "Done 2680000\n",
      "Done 2690000\n",
      "Done 2700000\n",
      "Done 2710000\n",
      "Done 2720000\n",
      "Done 2730000\n",
      "Done 2740000\n",
      "Done 2750000\n",
      "Done 2760000\n",
      "Done 2770000\n",
      "Done 2780000\n",
      "Done 2790000\n",
      "Done 2800000\n",
      "Done 2810000\n",
      "Done 2820000\n",
      "Done 2830000\n",
      "Done 2840000\n",
      "Done 2850000\n",
      "Done 2860000\n",
      "Done 2870000\n",
      "Done 2880000\n",
      "Done 2890000\n",
      "Done 2900000\n",
      "Done 2910000\n",
      "Done 2920000\n",
      "Done 2930000\n",
      "Done 2940000\n",
      "Done 2950000\n",
      "Done 2960000\n",
      "Done 2970000\n",
      "Done 2980000\n",
      "Done 2990000\n",
      "Done 3000000\n",
      "Done 3010000\n",
      "Done 3020000\n",
      "Done 3030000\n",
      "Done 3040000\n",
      "Done 3050000\n",
      "Done 3060000\n",
      "Done 3070000\n",
      "Done 3080000\n",
      "Done 3090000\n",
      "Done 3100000\n",
      "Done 3110000\n",
      "Done 3120000\n",
      "Done 3130000\n",
      "Done 3140000\n",
      "Done 3150000\n",
      "Done 3160000\n",
      "Done 3170000\n",
      "Done 3180000\n",
      "Done 3190000\n",
      "Done 3200000\n",
      "Done 3210000\n",
      "Done 3220000\n",
      "Done 3230000\n",
      "Done 3240000\n",
      "Done 3250000\n",
      "Done 3260000\n",
      "Done 3270000\n",
      "Done 3280000\n",
      "Done 3290000\n",
      "Done 3300000\n",
      "Done 3310000\n",
      "Done 3320000\n",
      "Done 3330000\n",
      "Done 3340000\n",
      "Done 3350000\n",
      "Done 3360000\n",
      "Done 3370000\n",
      "Done 3380000\n",
      "Done 3390000\n",
      "Done 3400000\n",
      "Done 3410000\n",
      "Done 3420000\n",
      "Done 3430000\n",
      "Done 3440000\n",
      "Done 3450000\n",
      "Done 3460000\n",
      "Done 3470000\n",
      "Done 3480000\n",
      "Done 3490000\n",
      "Done 3500000\n",
      "Done 3510000\n",
      "Done 3520000\n",
      "Done 3530000\n",
      "Done 3540000\n",
      "Done 3550000\n",
      "Done 3560000\n",
      "Done 3570000\n",
      "Done 3580000\n",
      "Done 3590000\n",
      "Done 3600000\n",
      "Done 3610000\n",
      "Done 3620000\n",
      "Done 3630000\n",
      "Done 3640000\n",
      "Done 3650000\n",
      "Done 3660000\n",
      "Done 3670000\n",
      "Done 3680000\n",
      "Done 3690000\n",
      "Done 3700000\n",
      "Done 3710000\n",
      "Done 3720000\n",
      "Done 3730000\n",
      "Done 3740000\n",
      "Done 3750000\n",
      "Done 3760000\n",
      "Done 3770000\n",
      "Done 3780000\n",
      "Done 3790000\n",
      "Done 3800000\n",
      "Done 3810000\n",
      "Done 3820000\n",
      "Done 3830000\n",
      "Done 3840000\n",
      "Done 3850000\n",
      "Done 3860000\n",
      "Done 3870000\n",
      "Done 3880000\n",
      "Done 3890000\n",
      "Done 3900000\n",
      "Done 3910000\n",
      "Done 3920000\n",
      "Done 3930000\n",
      "Done 3940000\n",
      "Done 3950000\n",
      "Done 3960000\n",
      "Done 3970000\n",
      "Done 3980000\n",
      "Done 3990000\n",
      "Done 4000000\n",
      "Done 4010000\n",
      "Done 4020000\n",
      "Done 4030000\n",
      "Done 4040000\n",
      "Done 4050000\n",
      "Done 4060000\n",
      "Done 4070000\n",
      "Done 4080000\n",
      "Done 4090000\n",
      "Done 4100000\n",
      "Done 4110000\n",
      "Done 4120000\n",
      "Done 4130000\n",
      "Done 4140000\n",
      "Done 4150000\n",
      "Done 4160000\n",
      "Done 4170000\n",
      "Done 4180000\n",
      "Done 4190000\n",
      "Done 4200000\n",
      "Done 4210000\n",
      "Done 4220000\n",
      "Done 4230000\n",
      "Done 4240000\n",
      "Done 4250000\n",
      "Done 4260000\n",
      "Done 4270000\n",
      "Done 4280000\n",
      "Done 4290000\n",
      "Done 4300000\n",
      "Done 4310000\n",
      "Done 4320000\n",
      "Done 4330000\n",
      "Done 4340000\n",
      "Done 4350000\n",
      "Done 4360000\n",
      "Done 4370000\n",
      "Done 4380000\n",
      "Done 4390000\n",
      "Done 4400000\n",
      "Done 4410000\n",
      "Done 4420000\n",
      "Done 4430000\n",
      "Done 4440000\n",
      "Done 4450000\n",
      "Done 4460000\n",
      "Done 4470000\n",
      "Done 4480000\n",
      "Done 4490000\n",
      "Done 4500000\n",
      "Done 4510000\n",
      "Done 4520000\n",
      "Done 4530000\n",
      "Done 4540000\n",
      "Done 4550000\n",
      "Done 4560000\n",
      "Done 4570000\n",
      "Done 4580000\n",
      "Done 4590000\n",
      "Done 4600000\n",
      "Done 4610000\n",
      "Done 4620000\n",
      "Done 4630000\n",
      "Done 4640000\n",
      "Done 4650000\n",
      "Done 4660000\n",
      "Done 4670000\n",
      "Done 4680000\n",
      "Done 4690000\n",
      "Done 4700000\n",
      "Done 4710000\n",
      "Done 4720000\n",
      "Done 4730000\n",
      "Done 4740000\n",
      "Done 4750000\n",
      "Done 4760000\n",
      "Done 4770000\n",
      "Done 4780000\n",
      "Done 4790000\n",
      "Done 4800000\n",
      "Done 4810000\n",
      "Done 4820000\n",
      "Done 4830000\n",
      "Done 4840000\n",
      "Done 4850000\n",
      "Done 4860000\n",
      "Done 4870000\n",
      "Done 4880000\n",
      "Done 4890000\n",
      "Done 4900000\n",
      "Done 4910000\n",
      "Done 4920000\n",
      "Done 4930000\n",
      "Done 4940000\n",
      "Done 4950000\n",
      "Done 4960000\n",
      "Done 4970000\n",
      "Done 4980000\n",
      "Done 4990000\n",
      "Done 5000000\n",
      "Done 5010000\n",
      "Done 5020000\n",
      "Done 5030000\n",
      "Done 5040000\n",
      "Done 5050000\n",
      "Done 5060000\n",
      "Done 5070000\n",
      "Done 5080000\n",
      "Done 5090000\n",
      "Done 5100000\n",
      "Done 5110000\n",
      "Done 5120000\n",
      "Done 5130000\n",
      "Done 5140000\n",
      "Done 5150000\n",
      "Done 5160000\n",
      "Done 5170000\n",
      "Done 5180000\n",
      "Done 5190000\n",
      "Done 5200000\n",
      "Done 5210000\n",
      "Done 5220000\n",
      "Done 5230000\n",
      "Done 5240000\n",
      "Done 5250000\n",
      "Done 5260000\n",
      "Done 5270000\n",
      "Done 5280000\n",
      "Done 5290000\n",
      "Done 5300000\n",
      "Done 5310000\n",
      "Done 5320000\n",
      "Done 5330000\n",
      "Done 5340000\n",
      "Done 5350000\n",
      "Done 5360000\n",
      "Done 5370000\n",
      "Done 5380000\n",
      "Done 5390000\n",
      "Done 5400000\n",
      "Done 5410000\n",
      "Done 5420000\n",
      "Done 5430000\n",
      "Done 5440000\n",
      "Done 5450000\n",
      "Done 5460000\n",
      "Done 5470000\n",
      "Done 5480000\n",
      "Done 5490000\n",
      "Done 5500000\n",
      "Done 5510000\n",
      "Done 5520000\n",
      "Done 5530000\n",
      "Done 5540000\n",
      "Done 5550000\n",
      "Done 5560000\n",
      "Done 5570000\n",
      "Done 5580000\n",
      "Done 5590000\n",
      "Done 5600000\n",
      "Done 5610000\n",
      "Done 5620000\n",
      "Done 5630000\n",
      "Done 5640000\n",
      "Done 5650000\n",
      "Done 5660000\n",
      "Done 5670000\n",
      "Done 5680000\n",
      "Done 5690000\n",
      "Done 5700000\n",
      "Done 5710000\n",
      "Done 5720000\n",
      "Done 5730000\n",
      "Done 5740000\n",
      "Done 5750000\n",
      "Done 5760000\n",
      "Done 5770000\n",
      "Done 5780000\n",
      "Done 5790000\n",
      "Done 5800000\n",
      "Done 5810000\n",
      "Done 5820000\n",
      "Done 5830000\n",
      "Done 5840000\n",
      "Done 5850000\n",
      "Done 5860000\n",
      "Done 5870000\n",
      "Done 5880000\n",
      "Done 5890000\n",
      "Done 5900000\n",
      "Done 5910000\n",
      "Done 5920000\n",
      "Done 5930000\n",
      "Done 5940000\n",
      "Done 5950000\n",
      "Done 5960000\n",
      "Done 5970000\n",
      "Done 5980000\n",
      "Done 5990000\n",
      "Done 6000000\n"
     ]
    }
   ],
   "source": [
    "scores_ism = np.array(ism_func(input_data_list=[onehot_data],\n",
    "                                       progress_update=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 400, 4)\n"
     ]
    }
   ],
   "source": [
    "print(scores_ism.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00 -0.00000000e+00  0.00000000e+00 -4.92358208e-03]\n",
      " [ 9.63139534e-03 -0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 4.46605682e-03  0.00000000e+00 -0.00000000e+00 -0.00000000e+00]\n",
      " ...\n",
      " [ 0.00000000e+00 -0.00000000e+00 -0.00000000e+00  4.76837158e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00 -0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -7.15255737e-07  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(scores_ism[2144])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('/users/eprakash/projects/benchmarking/newdata/A549/models/deepseabeluga/results/A549.deepseabeluga.ISM.scores.5Ksubsample.npy', scores_ism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
