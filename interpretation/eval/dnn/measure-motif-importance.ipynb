{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import h5py\n",
    "import numpy as np\n",
    "import deeplift\n",
    "import evautils\n",
    "from scipy import stats\n",
    "from evautils import sequtils\n",
    "from evautils import kerasutils\n",
    "from evautils import dirutils\n",
    "from evautils import windowscoringutils\n",
    "from evautils import impscoringutils\n",
    "from collections import OrderedDict, defaultdict\n",
    "import os\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    roc_curve, precision_recall_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION_SIZE = 400\n",
    "POS_LABELS = '/users/eprakash/git/interpret-benchmark/data/dnase_positives/common_scripts/A549/sequences/top_10k_sim_positives.txt.gz'\n",
    "MOTIF_MATCHES='/users/eprakash/git/interpret-benchmark/data/dnase_positives/common_scripts/A549/sequences/reduced_sim_fimo_out/fimo.txt'\n",
    "SCORES = '/users/eprakash/git/interpret-benchmark/scripts/deepsea_beluga/A549/sim_pos_and_neg.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loading /users/eprakash/git/interpret-benchmark/data/dnase_positives/common_scripts/A549/sequences/reduced_sim_fimo_out/fimo.txt ...\n",
      "#Loaded 4623218 motif matches in 879553 sequences\n"
     ]
    }
   ],
   "source": [
    "motif_matches=sequtils.load_fimo_motif_matches(MOTIF_MATCHES, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import gzip\n",
    "import numpy as np\n",
    "def load_labels_from_bedfile(seqfile):\n",
    "    seqs = []\n",
    "    fp = gzip.open(seqfile, \"rb\")\n",
    "    print(\"#Loading \" + seqfile + \" ...\")\n",
    "    for line in fp:\n",
    "        line=line.decode('utf8').split()\n",
    "        seqs.append(line[0])\n",
    "    fp.close()\n",
    "    print(\"#Loaded \" + str(len(seqs)) + \" seqnames from \" + seqfile)\n",
    "    return np.array(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loading /users/eprakash/git/interpret-benchmark/data/dnase_positives/common_scripts/A549/sequences/top_10k_sim_positives.txt.gz ...\n",
      "#Loaded 10000 seqnames from /users/eprakash/git/interpret-benchmark/data/dnase_positives/common_scripts/A549/sequences/top_10k_sim_positives.txt.gz\n",
      "<KeysViewHDF5 ['deeplift-rcrs_ref:allzeros', 'deeplift-rcrs_ref:avgc', 'deeplift-rcrs_ref:shuff-20', 'deeplift-rs_ref:allzeros', 'deeplift-rs_ref:avgc', 'deeplift-rs_ref:shuff-20', 'gradtimesinp_ref:allzeros', 'ig-20_ref:shuff-20', 'ism', 'seqids']>\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File(SCORES,'r')\n",
    "pos_labels = load_labels_from_bedfile(POS_LABELS)\n",
    "print(h5f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplift_rcrs_allzeros_scores=np.array(h5f.get(\"deeplift-rcrs_ref:allzeros\"))\n",
    "deeplift_rcrs_avgc_scores=np.array(h5f.get(\"deeplift-rcrs_ref:avgc\"))\n",
    "deeplift_rcrs_shuff10_scores=np.array(h5f.get(\"deeplift-rcrs_ref:shuff-10\"))\n",
    "deeplift_rcrs_shuff20_scores=np.array(h5f.get(\"deeplift-rcrs_ref:shuff-20\"))\n",
    "\n",
    "deeplift_rs_allzeros_scores=np.array(h5f.get(\"deeplift-rs_ref:allzeros\"))\n",
    "deeplift_rs_avgc_scores=np.array(h5f.get(\"deeplift-rs_ref:avgc\"))\n",
    "deeplift_rs_shuff10_scores=np.array(h5f.get(\"deeplift-rs_ref:shuff-10\"))\n",
    "deeplift_rs_shuff20_scores=np.array(h5f.get(\"deeplift-rs_ref:shuff-20\"))\n",
    "\n",
    "gradcam_scores = np.array(h5f.get(\"gradcam\"))\n",
    "gradtimesact_direct_scores = np.array(h5f.get(\"gradtimesact-direct\"))\n",
    "\n",
    "\n",
    "grad_times_input_allzeros_scores = np.array(h5f.get(\"gradtimesinp_ref:allzeros\"))\n",
    "grad_times_input_avgc_scores = np.array(h5f.get(\"gradtimesinp_ref:avgc\"))\n",
    "grad_times_input_shuff10_scores = np.array(h5f.get(\"gradtimesinp_ref:shuff-10\"))\n",
    "grad_times_input_shuff20_scores = np.array(h5f.get(\"gradtimesinp_ref:shuff-20\"))\n",
    "\n",
    "\n",
    "ism_scores = np.array(h5f.get(\"ism\"))\n",
    "\n",
    "ig10_shuff10_scores = np.array(h5f.get(\"ig-10_ref:shuff-10\"))\n",
    "ig10_shuff20_scores =np.array(h5f.get(\"ig-10_ref:shuff-20\"))\n",
    "ig20_shuff10_scores =np.array(h5f.get(\"ig-20_ref:shuff-10\"))\n",
    "ig20_shuff20_scores =np.array(h5f.get(\"ig-20_ref:shuff-20\"))\n",
    "\n",
    "seqids = [x.decode('utf-8') for x in np.array(h5f.get(\"seqids\"))]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def interpolate_scores(method_scores):\n",
    "    leftover_sequence_length = 10\n",
    "    effective_input_length = REGION_SIZE - leftover_sequence_length\n",
    "    ret = np.zeros((method_scores.shape[0], REGION_SIZE))\n",
    "    print(ret.shape)\n",
    "    for i in range(len(method_scores)):\n",
    "        scores = method_scores[i]\n",
    "        multiplication_factor = float(effective_input_length)/(len(scores)+1)\n",
    "        interpolated_scores = interp1d(x=(np.arange(len(scores))+1)*multiplication_factor, y=scores, kind=\"linear\", fill_value=\"extrapolate\", bounds_error=False)(0.5+np.arange(effective_input_length))\n",
    "        interpolated_scores = np.pad(interpolated_scores, (0,leftover_sequence_length), 'constant')\n",
    "        ret[i] = interpolated_scores\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplift_rcrs_allzeros_scores = interpolate_scores(deeplift_rcrs_allzeros_scores)\n",
    "deeplift_rcrs_avgc_scores = interpolate_scores(deeplift_rcrs_avgc_scores)\n",
    "deeplift_rcrs_shuff10_scores = interpolate_scores(deeplift_rcrs_shuff10_scores)\n",
    "deeplift_rcrs_shuff20_scores = interpolate_scores(deeplift_rcrs_shuff20_scores)\n",
    "\n",
    "deeplift_rs_allzeros_scores = interpolate_scores(deeplift_rs_allzeros_scores)\n",
    "deeplift_rs_avgc_scores = interpolate_scores(deeplift_rs_avgc_scores)\n",
    "deeplift_rs_shuff10_scores = interpolate_scores(deeplift_rs_shuff10_scores)\n",
    "deeplift_rs_shuff20_scores = interpolate_scores(deeplift_rs_shuff20_scores)\n",
    "\n",
    "gradcam_scores = interpolate_scores(gradcam_scores)\n",
    "gradtimesact_direct_scores = interpolate_scores(gradtimesact_direct_scores)\n",
    "\n",
    "\n",
    "grad_times_input_allzeros_scores = interpolate_scores(grad_times_input_allzeros_scores)\n",
    "grad_times_input_avgc_scores = interpolate_scores(grad_times_input_avgc_scores)\n",
    "grad_times_input_shuff10_scores = interpolate_scores(grad_times_input_shuff10_scores)\n",
    "grad_times_input_shuff20_scores = interpolate_scores(grad_times_input_shuff20_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Loading /users/eprakash/git/interpret-benchmark/data/dnase_positives/common_scripts/A549/sequences/reduced_sim_fimo_out/fimo.txt ...\n",
      "#Loaded 4623218 motif matches in 879553 sequences\n",
      "879553\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "motif_matches=sequtils.load_fimo_motif_matches(MOTIF_MATCHES, True)\n",
    "print(len(motif_matches))\n",
    "for key in list(motif_matches.keys()):\n",
    "    if key not in pos_labels:\n",
    "        del motif_matches[key]\n",
    "print(len(motif_matches))\n",
    "seq_ids_of_interest = list(motif_matches.keys())\n",
    "print(len(seq_ids_of_interest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motif matches sequences are 10000\n",
      "Supplied labels are 10000\n"
     ]
    }
   ],
   "source": [
    "seq_ids_of_interest_set = set(seq_ids_of_interest)\n",
    "relevant_indices_list, relevant_labels_list=sequtils.get_relevant_labels_in_order_of_scores(seqids, motif_matches)\n",
    "seq_ids_of_interest = relevant_labels_list\n",
    "seq_ids_of_interest_set = set(relevant_labels_list)\n",
    "\n",
    "deeplift_rcrs_allzeros_scores=sequtils.get_relevant_scores(relevant_indices_list, deeplift_rcrs_allzeros_scores, REGION_SIZE)\n",
    "deeplift_rcrs_avgc_scores=sequtils.get_relevant_scores(relevant_indices_list, deeplift_rcrs_avgc_scores, REGION_SIZE)\n",
    "#deeplift_rcrs_shuff10_scores=sequtils.get_relevant_scores(relevant_indices_list, deeplift_rcrs_shuff10_scores, REGION_SIZE)\n",
    "deeplift_rcrs_shuff20_scores=sequtils.get_relevant_scores(relevant_indices_list, deeplift_rcrs_shuff20_scores, REGION_SIZE)\n",
    "\n",
    "deeplift_rs_allzeros_scores=sequtils.get_relevant_scores(relevant_indices_list, deeplift_rs_allzeros_scores, REGION_SIZE)\n",
    "deeplift_rs_avgc_scores=sequtils.get_relevant_scores(relevant_indices_list, deeplift_rs_avgc_scores, REGION_SIZE)\n",
    "#deeplift_rs_shuff10_scores=sequtils.get_relevant_scores(relevant_indices_list, deeplift_rs_shuff10_scores, REGION_SIZE)\n",
    "deeplift_rs_shuff20_scores=sequtils.get_relevant_scores(relevant_indices_list, deeplift_rs_shuff20_scores, REGION_SIZE)\n",
    "\n",
    "grad_times_input_allzeros_scores = sequtils.get_relevant_scores(relevant_indices_list, grad_times_input_allzeros_scores, REGION_SIZE)\n",
    "#grad_times_input_avgc_scores = sequtils.get_relevant_scores(relevant_indices_list, grad_times_input_avgc_scores, REGION_SIZE)\n",
    "#grad_times_input_shuff10_scores = sequtils.get_relevant_scores(relevant_indices_list, grad_times_input_shuff10_scores, REGION_SIZE)\n",
    "#grad_times_input_shuff20_scores = sequtils.get_relevant_scores(relevant_indices_list, grad_times_input_shuff20_scores, REGION_SIZE)\n",
    "\n",
    "#gradcam_scores = sequtils.get_relevant_scores(relevant_indices_list, gradcam_scores, REGION_SIZE)\n",
    "#gradtimesact_direct_scores = sequtils.get_relevant_scores(relevant_indices_list, gradtimesact_direct_scores, REGION_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_to_saved_scores = OrderedDict([('deeplift_rcrs_shuff20', deeplift_rcrs_shuff20_scores),\n",
    "                                      ('deeplift_rs_shuff20', deeplift_rs_shuff20_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count all motifs percentage\n",
    "num_labels = len(relevant_labels_list)\n",
    "print(\"Num labels is \" + str(num_labels))\n",
    "per_seq_percentages = []\n",
    "fp = open('no_neg_implant_percents.txt', 'w+')\n",
    "for method in method_to_saved_scores:\n",
    "    total_sum_importance=0\n",
    "    motif_sum_importance=0\n",
    "    for seq in range(num_labels):\n",
    "        motif_positions = set({})\n",
    "        label = relevant_labels_list[seq]\n",
    "        index = relevant_indices_list[seq]\n",
    "        total_per_seq_importance = np.sum(np.abs(method_to_saved_scores[method][index]))\n",
    "        total_sum_importance = total_sum_importance + total_per_seq_importance\n",
    "        seqentries = motif_matches[label]\n",
    "        motif_per_seq_importance = 0\n",
    "        for entry in seqentries:\n",
    "            motif_positions.update(range(entry['begin'], entry['end']))\n",
    "        for i in motif_positions:\n",
    "            motif_per_seq_importance = motif_per_seq_importance + np.abs(method_to_saved_scores[method][index][i])\n",
    "            motif_sum_importance = motif_sum_importance + np.abs(method_to_saved_scores[method][index][i])\n",
    "        per_seq_percentages.append(float(motif_per_seq_importance)/float(total_per_seq_importance))\n",
    "    percentage = float(motif_sum_importance)/float(total_sum_importance)\n",
    "    print(\"Method is \" + str(method))\n",
    "    print(\"Total summed importance \" + str(total_sum_importance))\n",
    "    print(\"Motif region summed importance  \" + str(motif_sum_importance))\n",
    "    print(\"Total percentage \" + str(percentage*100))\n",
    "    print(\"Mean per sequence percentage \" + str(np.mean(np.array(per_seq_percentages))))\n",
    "    print(\"Standard error \" + str(stats.sem(per_seq_percentages)))\n",
    "    print(\"\\n\")\n",
    "    assert(len(per_seq_percentages) == 10000)\n",
    "    per_seq_percentages.clear()\n",
    "    fp.write(method + \": [\" + str(percentage) + \", \" + str(np.mean(np.array(per_seq_percentages))) + \"]\\n\")\n",
    "fp.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(relevant_labels_list)\n",
    "print(\"Num labels is \" + str(num_labels))\n",
    "per_seq_diffs = []\n",
    "bad_ig = []\n",
    "#fp = open('sim_pos_and_neg_diffs.txt', 'w+')\n",
    "for method in method_to_saved_scores:\n",
    "    total_sum_importance=0\n",
    "    motif_sum_importance=0\n",
    "    for seq in range(num_labels):\n",
    "        motif_positions = set({})\n",
    "        label = relevant_labels_list[seq]\n",
    "        index = relevant_indices_list[seq]\n",
    "        total_per_seq_abs_importance = np.sum(np.abs(method_to_saved_scores[method][index]))\n",
    "        total_per_seq_importance = np.sum(method_to_saved_scores[method][index])\n",
    "        total_sum_importance = total_sum_importance + (total_per_seq_importance/total_per_seq_abs_importance)\n",
    "        seqentries = motif_matches[label]\n",
    "        motif_per_seq_importance = 0\n",
    "        for entry in seqentries:\n",
    "            motif_positions.update(range(entry['begin'], entry['end']))\n",
    "        for i in motif_positions:\n",
    "            motif_per_seq_importance = motif_per_seq_importance + (method_to_saved_scores[method][index][i])/total_per_seq_abs_importance\n",
    "            motif_sum_importance = motif_sum_importance + (method_to_saved_scores[method][index][i])/total_per_seq_abs_importance\n",
    "        seq_diff = motif_per_seq_importance*2-(total_per_seq_importance/total_per_seq_abs_importance)\n",
    "        if ('ig20_shuff20' == method and (seq_diff < 0)):\n",
    "            bad_ig.append(seq)\n",
    "        #if(seq == 2724):\n",
    "        #    print(method + \" \" + str(seq_diff))\n",
    "        per_seq_diffs.append(seq_diff)\n",
    "    diff = np.sum(per_seq_diffs)\n",
    "    print(\"Method is \" + str(method))\n",
    "    print(\"Non-motif region summed importance \" + str(total_sum_importance - motif_sum_importance))\n",
    "    print(\"Motif region summed importance  \" + str(motif_sum_importance))\n",
    "    print(\"Total difference \" + str(diff))\n",
    "    print(\"Mean per sequence difference \" + str(np.mean(np.array(per_seq_diffs))))\n",
    "    print(\"Standard error \" + str(stats.sem(per_seq_diffs)))\n",
    "    print(\"\\n\")\n",
    "    assert(len(per_seq_diffs) == 10000)\n",
    "    #fp.write(method + \": [\" + str(diff) + \", \" + str(np.mean(np.array(per_seq_diffs))) + \"]\\n\")\n",
    "    per_seq_diffs.clear()\n",
    "#fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bad_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(relevant_labels_list[156])\n",
    "print(relevant_labels_list[213])\n",
    "print(relevant_labels_list[2724])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(relevant_labels_list)\n",
    "print(\"Num labels is \" + str(num_labels))\n",
    "per_seq_aurocs = []\n",
    "per_seq_auprcs = []\n",
    "bad_ig = []\n",
    "good_deeplift = []\n",
    "#fp = open('gradcam_second_last_auroc_auprc.txt', 'w+')\n",
    "for method in list(method_to_saved_scores.keys()):\n",
    "    total_labels = np.array([])\n",
    "    total_scores = np.array([])\n",
    "    for seq in range(num_labels):\n",
    "        motif_positions = set({})\n",
    "        seqname = relevant_labels_list[seq]\n",
    "        index = relevant_indices_list[seq]\n",
    "        scores = np.abs(np.array(method_to_saved_scores[method][index]))\n",
    "        labels = np.zeros(REGION_SIZE)\n",
    "        seqentries = motif_matches[seqname]\n",
    "        for entry in seqentries:\n",
    "                motif_positions.update(range(entry['begin'], entry['end']))\n",
    "        for i in motif_positions:\n",
    "            labels[i] = 1\n",
    "        total_scores = np.concatenate((total_scores, scores))\n",
    "        total_labels = np.concatenate((total_labels, labels))\n",
    "        per_seq_aurocs.append(roc_auc_score(y_true=labels, y_score=scores))\n",
    "        per_seq_auprcs.append(average_precision_score(y_true=labels, y_score=scores))\n",
    "        \n",
    "    print(\"Method is \" + str(method))\n",
    "    print(\"Total auroc \" + str(roc_auc_score(y_true=total_labels, y_score=total_scores)))\n",
    "    print(\"Total auprc \" + str(average_precision_score(y_true=total_labels, y_score=total_scores)))\n",
    "    print(\"Mean per sequence auroc \" + str(np.mean(np.array(per_seq_aurocs))))\n",
    "    print(\"Mean per sequence auprc \" + str(np.mean(np.array(per_seq_auprcs))))\n",
    "    print(\"Per sequence auroc stderr \" + str(np.std(np.array(per_seq_aurocs))/np.sqrt(num_labels)))\n",
    "    print(\"Per sequence auprc stderr \" + str(np.std(np.array(per_seq_auprcs))/np.sqrt(num_labels)))\n",
    "    print(\"\\n\")\n",
    "    if ('ig20_shuff20' == method):\n",
    "        bad_ig = per_seq_auprcs.copy()\n",
    "    if ('deeplift_rs_shuff20' == method):\n",
    "        good_deeplift = per_seq_auprcs.copy()\n",
    "        \n",
    "    assert(len(per_seq_aurocs) == 10000)\n",
    "    \n",
    "    #fp.write(method + \": [\" + str(np.mean(np.array(per_seq_aurocs))) + \", \" + str(np.mean(np.array(per_seq_auprcs))) + \", \"\n",
    "#+ str(np.std(np.array(per_seq_aurocs))/np.sqrt(num_labels)) + \", \" + str(np.std(np.array(per_seq_auprcs))/np.sqrt(num_labels)) + \"]\\n\")\n",
    "    \n",
    "    per_seq_aurocs.clear()\n",
    "    per_seq_auprcs.clear()\n",
    "    \n",
    "#fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_labels = len(relevant_labels_list)\n",
    "print(\"Num labels is \" + str(num_labels))\n",
    "per_seq_aurocs = []\n",
    "per_seq_auprcs = []\n",
    "bad_ig = []\n",
    "good_deeplift = []\n",
    "#fp = open('gradcam_second_last_auroc_auprc.txt', 'w+')\n",
    "for method in list(method_to_saved_scores.keys()):\n",
    "    total_labels = np.array([])\n",
    "    total_scores = np.array([])\n",
    "    for seq in range(num_labels):\n",
    "        motif_positions = set({})\n",
    "        seqname = relevant_labels_list[seq]\n",
    "        index = relevant_indices_list[seq]\n",
    "        scores = np.abs(np.array(method_to_saved_scores[method][index]))\n",
    "        labels = np.zeros(REGION_SIZE)\n",
    "        seqentries = motif_matches[seqname]\n",
    "        for entry in seqentries:\n",
    "                motif_positions.update(range(entry['begin'], entry['end']))\n",
    "        for i in motif_positions:\n",
    "            labels[i] = 1\n",
    "        total_scores = np.concatenate((total_scores, scores))\n",
    "        total_labels = np.concatenate((total_labels, labels))\n",
    "        per_seq_aurocs.append(roc_auc_score(y_true=labels, y_score=scores))\n",
    "        per_seq_auprcs.append(average_precision_score(y_true=labels, y_score=scores))\n",
    "        \n",
    "    print(\"Method is \" + str(method))\n",
    "    print(\"Total auroc \" + str(roc_auc_score(y_true=total_labels, y_score=total_scores)))\n",
    "    print(\"Total auprc \" + str(average_precision_score(y_true=total_labels, y_score=total_scores)))\n",
    "    print(\"Mean per sequence auroc \" + str(np.mean(np.array(per_seq_aurocs))))\n",
    "    print(\"Mean per sequence auprc \" + str(np.mean(np.array(per_seq_auprcs))))\n",
    "    print(\"Per sequence auroc stderr \" + str(np.std(np.array(per_seq_aurocs))/np.sqrt(num_labels)))\n",
    "    print(\"Per sequence auprc stderr \" + str(np.std(np.array(per_seq_auprcs))/np.sqrt(num_labels)))\n",
    "    print(\"\\n\")\n",
    "    if ('ig20_shuff20' == method):\n",
    "        bad_ig = per_seq_auprcs.copy()\n",
    "    if ('deeplift_rs_shuff20' == method):\n",
    "        good_deeplift = per_seq_auprcs.copy()\n",
    "        \n",
    "    assert(len(per_seq_aurocs) == 10000)\n",
    "    \n",
    "    #fp.write(method + \": [\" + str(np.mean(np.array(per_seq_aurocs))) + \", \" + str(np.mean(np.array(per_seq_auprcs))) + \", \"\n",
    "#+ str(np.std(np.array(per_seq_aurocs))/np.sqrt(num_labels)) + \", \" + str(np.std(np.array(per_seq_auprcs))/np.sqrt(num_labels)) + \"]\\n\")\n",
    "    \n",
    "    per_seq_aurocs.clear()\n",
    "    per_seq_auprcs.clear()\n",
    "    \n",
    "#fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num labels is 10000\n",
      "Method is deeplift_rcrs_shuff20\n",
      "Total auroc 0.8644083377332255\n",
      "Total auprc 0.8080419276890749\n",
      "Mean per sequence auroc 0.8392018955117514\n",
      "Mean per sequence auprc 0.8062041347218181\n",
      "Per sequence auroc stderr 0.0009726599136625381\n",
      "Per sequence auprc stderr 0.0012614499611400605\n",
      "\n",
      "\n",
      "Method is deeplift_rs_shuff20\n",
      "Total auroc 0.8620843733991302\n",
      "Total auprc 0.8065082912273422\n",
      "Mean per sequence auroc 0.8374015736449127\n",
      "Mean per sequence auprc 0.8043050340589459\n",
      "Per sequence auroc stderr 0.0009818282226773496\n",
      "Per sequence auprc stderr 0.0012902395815216237\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(relevant_labels_list)\n",
    "print(\"Num labels is \" + str(num_labels))\n",
    "per_seq_aurocs = []\n",
    "per_seq_auprcs = []\n",
    "bad_ig = []\n",
    "good_deeplift = []\n",
    "#fp = open('gradcam_second_last_auroc_auprc.txt', 'w+')\n",
    "for method in list(method_to_saved_scores.keys()):\n",
    "    total_labels = np.array([])\n",
    "    total_scores = np.array([])\n",
    "    for seq in range(num_labels):\n",
    "        motif_positions = set({})\n",
    "        seqname = relevant_labels_list[seq]\n",
    "        index = relevant_indices_list[seq]\n",
    "        scores = np.abs(np.array(method_to_saved_scores[method][index]))\n",
    "        labels = np.zeros(REGION_SIZE)\n",
    "        seqentries = motif_matches[seqname]\n",
    "        for entry in seqentries:\n",
    "                motif_positions.update(range(entry['begin'], entry['end']))\n",
    "        for i in motif_positions:\n",
    "            labels[i] = 1\n",
    "        total_scores = np.concatenate((total_scores, scores))\n",
    "        total_labels = np.concatenate((total_labels, labels))\n",
    "        per_seq_aurocs.append(roc_auc_score(y_true=labels, y_score=scores))\n",
    "        per_seq_auprcs.append(average_precision_score(y_true=labels, y_score=scores))\n",
    "        \n",
    "    print(\"Method is \" + str(method))\n",
    "    print(\"Total auroc \" + str(roc_auc_score(y_true=total_labels, y_score=total_scores)))\n",
    "    print(\"Total auprc \" + str(average_precision_score(y_true=total_labels, y_score=total_scores)))\n",
    "    print(\"Mean per sequence auroc \" + str(np.mean(np.array(per_seq_aurocs))))\n",
    "    print(\"Mean per sequence auprc \" + str(np.mean(np.array(per_seq_auprcs))))\n",
    "    print(\"Per sequence auroc stderr \" + str(np.std(np.array(per_seq_aurocs))/np.sqrt(num_labels)))\n",
    "    print(\"Per sequence auprc stderr \" + str(np.std(np.array(per_seq_auprcs))/np.sqrt(num_labels)))\n",
    "    print(\"\\n\")\n",
    "    if ('ig20_shuff20' == method):\n",
    "        bad_ig = per_seq_auprcs.copy()\n",
    "    if ('deeplift_rs_shuff20' == method):\n",
    "        good_deeplift = per_seq_auprcs.copy()\n",
    "        \n",
    "    assert(len(per_seq_aurocs) == 10000)\n",
    "    \n",
    "    #fp.write(method + \": [\" + str(np.mean(np.array(per_seq_aurocs))) + \", \" + str(np.mean(np.array(per_seq_auprcs))) + \", \"\n",
    "#+ str(np.std(np.array(per_seq_aurocs))/np.sqrt(num_labels)) + \", \" + str(np.std(np.array(per_seq_auprcs))/np.sqrt(num_labels)) + \"]\\n\")\n",
    "    \n",
    "    per_seq_aurocs.clear()\n",
    "    per_seq_auprcs.clear()\n",
    "    \n",
    "#fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(bad_ig)):\n",
    "    ig_auprc = bad_ig[i]\n",
    "    dl_auprc = good_deeplift[i]\n",
    "    if (dl_auprc - ig_auprc > 0.2):\n",
    "        print(dl_auprc, ig_auprc, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bad_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(relevant_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_labels_list[910]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqids[910]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(seqids)):\n",
    "    if (seqids[i] == 'chr14:64937697-64938097'):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqids[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_deeplift[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ig[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
