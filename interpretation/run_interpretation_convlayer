#!/usr/bin/env python
from __future__ import division, print_function, absolute_import
import argparse
from vakai import util
import keras
import deeplift
from deeplift.util import compile_func
from deeplift.layers import NonlinearMxtsMode 
import deeplift.conversion.kerasapi_conversion as kc
from collections import OrderedDict
import tensorflow as tf
import configparser
import numpy as np
from deeplift.dinuc_shuffle import dinuc_shuffle
import h5py
import tensorflow as tf

def get_shuffle_seq_ref_function(score_computation_function, 
                                 shuffle_func, one_hot_func=None):
    def compute_scores_with_shuffle_seq_refs(
        task_idx, input_data_sequences, num_refs_per_seq,
        batch_size, seed=1, progress_update=None, pregen_refs=None):
        rng = np.random.RandomState(seed)
        if (pregen_refs is None):
            to_run_input_data_seqs = []
            to_run_input_data_refs = []
            references_generated = 0
            for seq in input_data_sequences:
                for i in range(num_refs_per_seq):
                    references_generated += 1
                    if (progress_update is not None and
                        references_generated%progress_update==0):
                        print(str(references_generated)
                              +" reference seqs generated")
                    if isinstance(seq,np.ndarray):
                        seq=seq.squeeze()
                    to_run_input_data_seqs.append(seq) 
                    to_run_input_data_refs.append(shuffle_func(seq,rng=rng))
        else:
            to_run_input_data_seqs = [seq for seq in input_data_sequences
                                      for i in range(num_refs_per_seq)]
            assert len(pregen_refs)==len(to_run_input_data_seqs),\
                   (len(pregen_refs), len(to_run_input_data_seqs))
            to_run_input_data_refs = pregen_refs
        if one_hot_func is not None:
            if (progress_update is not None):
                print("One hot encoding sequences...")
            input_data_list = [one_hot_func(to_run_input_data_seqs)] 
            input_references_list = [one_hot_func(to_run_input_data_refs)]
            if (progress_update is not None):
                print("One hot encoding done...")
        else:
            #the data is already one-hot encoded
            input_shape=list(input_data_sequences.shape)
            input_shape[0]=input_shape[0]*num_refs_per_seq
            input_shape=tuple(input_shape) 
            input_data_list = [np.reshape(np.asarray(to_run_input_data_seqs),
                                          input_shape)]
            input_references_list = [
                np.reshape(np.asarray(to_run_input_data_refs),input_shape)]
        #wrap task_idx in a list if it was not in a list
        # (will unwrap later)
        if (hasattr(task_idx, '__iter__')) == False:
            list_wrapped_task_idx = [task_idx]
        else:
            list_wrapped_task_idx = task_idx
        the_scores = []
        for a_task in list_wrapped_task_idx:
            computed_scores = np.array(score_computation_function(
                task_idx=a_task,
                input_data_list=input_data_list,
                input_references_list=input_references_list,
                batch_size=batch_size,
                progress_update=progress_update))
            computed_scores = np.reshape(
                                computed_scores,
                                [len(input_data_sequences),
                                 num_refs_per_seq]
                                 +list(computed_scores[0].shape))
            #take the mean over all the refs
            mean_scores = np.mean(computed_scores,axis=1)
            the_scores.append(mean_scores)
        #unwrap the scores if task_idx was not orginally a list
        if (hasattr(task_idx, '__iter__')) == False:
            the_scores = the_scores[0]
        return the_scores
    return compute_scores_with_shuffle_seq_refs

def sanity_check(converted_grad_model, keras_model, onehot_seqs):
    deeplift_prediction_func = compile_func(
        [converted_grad_model.get_layers()[0].get_activation_vars()],
         converted_grad_model.get_layers()[-1].get_activation_vars())
    keras_model_preds = keras_model.predict(onehot_seqs, batch_size=200)
    deeplift_model_preds = deeplift.util.run_function_in_batches(
                                input_data_list=[onehot_seqs],
                                func=deeplift_prediction_func,
                                batch_size=200,
                                progress_update=None)
    print("maximum difference in predictions:",
          np.max(np.array(deeplift_model_preds)
                 -np.array(keras_model_preds)))
    assert np.max(np.array(deeplift_model_preds)
                  -np.array(keras_model_preds)) < 10**-5

    #also do a sanity check for the gradients
    gradient_tensor = tf.gradients(keras_model.layers[-2].output[:,0],
                                   keras_model.input)[0]
    grad_calc_func = compile_func([keras_model.input], gradient_tensor)
    direct_calculated_grads = np.array(deeplift.util.run_function_in_batches(
                                input_data_list=[onehot_seqs],
                                func=grad_calc_func,
                                batch_size=200,
                                progress_update=None)) 
    converted_calculated_grads = np.array(
        converted_grad_model.get_target_multipliers_func(
            find_scores_layer_idx=0,
            target_layer_idx=-2)(task_idx=0,
                                 input_data_list=[onehot_seqs],
                                 batch_size=200,
                                 progress_update=None))
    print("maximum difference in calculated grads:",
          np.max(np.array(converted_calculated_grads)
                 -np.array(direct_calculated_grads)))
    assert np.max(np.array(converted_calculated_grads)
                  -np.array(direct_calculated_grads)) < 10**-5


def compile_scoring_functions(methodtype_to_deepliftmodel,
                              backprop_methods_set):
    if (any(['ig' in x for x in backprop_methods_set])):
        gradient_func = (methodtype_to_deepliftmodel['gradtimesinp']
                         .get_target_multipliers_func(find_scores_layer_idx=0,
                                                      target_layer_idx=-2)) 
    methodtype_to_scoringfunc = OrderedDict()  
    for methodtype in backprop_methods_set:
        if (methodtype in ['gradtimesinp', 'deeplift-rs', 'deeplift-rcrs']):
            deepliftmodel = methodtype_to_deepliftmodel[methodtype]
            methodtype_to_scoringfunc[methodtype] =\
                deepliftmodel.get_target_contribs_func(
                                find_scores_layer_idx=0,
                                target_layer_idx=-2)
        elif ('ig' in methodtype):
            num_intervals = int(methodtype.split("-")[1]) 
            integrated_gradients_func =\
                deeplift.util.get_integrated_gradients_function(
                  gradient_computation_function=gradient_func,
                  num_intervals=num_intervals)
            methodtype_to_scoringfunc[methodtype] = integrated_gradients_func
        else:
            raise RuntimeError("Unsupported methodtype:",methodtype) 
    return methodtype_to_scoringfunc


def get_methodtype_to_deepliftmodel(keras_model_h5, keras_model_json):
    methodtype_to_deepliftmodel = OrderedDict()
    for methodtype, nonlinear_mxts_mode in [
               ('deeplift-rs', NonlinearMxtsMode.Rescale),
               ('deeplift-rcrs', NonlinearMxtsMode.DeepLIFT_GenomicsDefault),
               ('gradtimesinp', NonlinearMxtsMode.Gradient)]:
        methodtype_to_deepliftmodel[methodtype] =\
            kc.convert_model_from_saved_files(
                h5_file=keras_model_h5,
                json_file=keras_model_json,
                nonlinear_mxts_mode=nonlinear_mxts_mode)
    return methodtype_to_deepliftmodel


def compute_and_write_scores_flatref(
        methodtypes, methodtype_to_scoringfunc,
        onehot_seqs, output_h5, batch_size, flatref,
        referencename):
    for methodtype in methodtypes:
        datasetname = methodtype+"_ref:"+referencename
        print("Computing scores for "+datasetname)
        score_func = methodtype_to_scoringfunc[methodtype]
        scores = np.array(score_func(
                    task_idx=0,
                    input_data_list=[onehot_seqs],
                    input_references_list=[flatref],
                    batch_size=batch_size,
                    progress_update=1000))
        assert len(scores.shape)==3
        scores = np.sum(scores, axis=2)
        if (datasetname in output_h5):
            print("WARNING: "+datasetname+" already exists!!! Won't overwrite")
        else:
            output_h5.create_dataset(datasetname, data=scores)


def compute_and_write_scores_zeroref(**kwargs):
    flatref = np.zeros(4)[None,None,:]
    compute_and_write_scores_flatref(
        flatref=flatref, referencename='allzeros', **kwargs)


def compute_and_write_scores_avgref(onehot_seqs, **kwargs):
    flatref = np.mean(onehot_seqs, axis=(0,1))[None,None,:]
    compute_and_write_scores_flatref(
        onehot_seqs=onehot_seqs,
        flatref=flatref, referencename='avgc', **kwargs)


def compute_and_write_scores_shuffref(methodtypes, methodtype_to_scoringfunc,
                                      onehot_seqs, output_h5, batch_size,
                                      num_shuffrefs):
    #pregenerate the shuffling
    rng = np.random.RandomState(1)
    max_num_shuffref = max(num_shuffrefs)
    print("MAX NUM SHUFFREF ", max_num_shuffref)
    shuffled_seqs = []
    for i in range(len(onehot_seqs)):
        if (i%100==0):
            print("Generating shuffled seqs for seq "+str(i))
        shuffled_seqs.append([
            dinuc_shuffle(onehot_seqs[i], rng=rng)
            for x in range(max_num_shuffref)])
    shuffled_seqs = np.array(shuffled_seqs) 

    for methodtype in methodtypes:
        for num_shuffref in num_shuffrefs: 
            datasetname = methodtype+"_ref:shuff-"+str(num_shuffref)
            print("Computing scores for "+datasetname)
            score_func = get_shuffle_seq_ref_function(
                score_computation_function=
                  methodtype_to_scoringfunc[methodtype],
                shuffle_func=None,#dinuc_shuffle,
                #onehot_func is the None because the input should
                # already be one-hot encoded
                one_hot_func=None)
            print("SHAPE: ", shuffled_seqs.shape)
            scores = np.array(score_func(
                        task_idx=0,
                        input_data_sequences=onehot_seqs,
                        num_refs_per_seq=num_shuffref,
                        batch_size=batch_size,
                        progress_update=1000,
                        pregen_refs=shuffled_seqs[:,:num_shuffref,:,:].reshape(
                         (-1, onehot_seqs.shape[1], onehot_seqs.shape[2]))
                        ))
            assert len(scores.shape)==3
            scores = np.sum(scores, axis=2)
            if (datasetname in output_h5):
                print("WARNING: "+datasetname
                      +" already exists!!! Won't overwrite")
            else:
                output_h5.create_dataset(datasetname, data=scores)


def run_interpretation(cfg, args):
    zeroref_methods = cfg['ZEROREF_METHODS'].split(",")
    avgc_methods = cfg['AVGC_METHODS'].split(",") 
    shuffref_methods = cfg['SHUFF_REF_METHODS'].split(",")
    num_shuffrefs = [int(x) for x in cfg['NUM_SHUFF_REFS'].split(",")]
    run_ism = cfg.getboolean('RUNISM')    
    batch_size = cfg.getint('BATCH_SIZE')
    
    find_scores_layer_idx = args.find_scores_layer_idx
    backprop_methods_set = set(zeroref_methods+avgc_methods+shuffref_methods)

    seqids = [(x.decode('utf-8') if hasattr(x,'decode') else x)
              .rstrip().split("\t")[0] for x in
              util.open_fh(args.input_seqs_file)]
    sequences = [(x.decode('utf-8') if hasattr(x,'decode') else x)
                  .rstrip().split()[1] for x in
                 util.open_fh(args.input_seqs_file)] 
    onehot_seqs = util.one_hot_encode(seqs=sequences)
    keras_model_h5 = args.keras_model_h5
    keras_model_json = args.keras_model_json
    if (keras_model_json is None):
        keras_model = keras.models.load_model(keras_model_h5)
    else:
        keras_model = util.load_keras_model_using_json(
                           json_file_name=keras_model_json,
                           h5_weights_file=keras_model_h5)

    print("LAYER ", keras_model.layers[find_scores_layer_idx])
    output_h5 = h5py.File(args.output_h5_file)
    if ("seqids" in output_h5):
        print("seqids entry already created in",args.output_h5_file)
    else:
        output_h5.create_dataset("seqids", data=np.array(seqids, dtype='S'))
   
    #define a function for computing gradcam importance
    conv_gradient_tensor = tf.gradients(keras_model.layers[-2].output[:,0],
                                   keras_model.layers[find_scores_layer_idx].output)[0]
    conv_grad_calc_func = compile_func([keras_model.input], conv_gradient_tensor)
    conv_activation_calc_func = compile_func([keras_model.input], keras_model.layers[find_scores_layer_idx].output)
    conv_grads = np.array(deeplift.util.run_function_in_batches(
                                input_data_list=[onehot_seqs],
                                func=conv_grad_calc_func,
                                batch_size=200,
                                progress_update=None)) 
    conv_activations = np.array(deeplift.util.run_function_in_batches(
                                input_data_list=[onehot_seqs],
                                func=conv_activation_calc_func,
                                batch_size=200,
                                progress_update=None))
    conv_grad_times_activation = conv_activations*conv_grads
    conv_avg_grad_per_channel = np.mean(conv_grads, axis=-1)
    conv_gradcam = conv_activations*conv_avg_grad_per_channel[:,:,None]
    perposition_conv_grad_times_activation = np.sum(conv_grad_times_activation, axis=-1)
    perposition_gradcam = np.maximum(np.sum(conv_gradcam, axis=-1), 0)
    output_h5.create_dataset("gradcam", data=perposition_gradcam)
    output_h5.create_dataset("gradtimesact-direct", data=perposition_conv_grad_times_activation)
    
    methodtype_to_deepliftmodel = get_methodtype_to_deepliftmodel(keras_model_h5, keras_model_json)
    methodtype_to_scoringfunc = OrderedDict()  
    for methodtype in backprop_methods_set:
        if (methodtype in ['gradtimesinp', 'deeplift-rs', 'deeplift-rcrs']):
            deepliftmodel = methodtype_to_deepliftmodel[methodtype]
            methodtype_to_scoringfunc[methodtype] =\
                deepliftmodel.get_target_contribs_func(
                                find_scores_layer_idx=find_scores_layer_idx+1,
                                target_layer_idx=-2)
        else:
            assert False, "only do gradtimesinp/deeplift-rs/deeplift-rcrs for now"

    compute_and_write_scores_zeroref(
        methodtypes=zeroref_methods,
        methodtype_to_scoringfunc=methodtype_to_scoringfunc,
        onehot_seqs=onehot_seqs, output_h5=output_h5, batch_size=batch_size)
    compute_and_write_scores_avgref(
        methodtypes=avgc_methods,
        methodtype_to_scoringfunc=methodtype_to_scoringfunc,
        onehot_seqs=onehot_seqs, output_h5=output_h5, batch_size=batch_size)
    compute_and_write_scores_shuffref(
        methodtypes=shuffref_methods,
        methodtype_to_scoringfunc=methodtype_to_scoringfunc,
        onehot_seqs=onehot_seqs, output_h5=output_h5, batch_size=batch_size,
        num_shuffrefs=num_shuffrefs)
    output_h5.close()


if __name__=='__main__':
    parser = argparse.ArgumentParser() 
    parser.add_argument("--configfile", required=True)
    parser.add_argument("--input_seqs_file", required=True)
    parser.add_argument("--keras_model_h5", required=True)
    parser.add_argument("--keras_model_json")
    parser.add_argument("--output_h5_file", required=True)
    parser.add_argument("--find_scores_layer_idx", type=int, default=13, required=True)
    args = parser.parse_args()
    cfg = configparser.ConfigParser() 
    cfg.read(args.configfile)
    run_interpretation(cfg['INTERPRETATION'], args)
