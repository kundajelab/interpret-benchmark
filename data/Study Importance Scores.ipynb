{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/avanti/interpret-benchmark/data/HepG2\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division, print_function\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "cell_type = \"HepG2\"\n",
    "%cd $cell_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12394\r\n"
     ]
    }
   ],
   "source": [
    "!zcat positives_not_in_small_valid_labels.gz | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load positives not seen in training or validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bed file positives_not_in_small_valid_labels.gz into memory\n",
      "Finished reading bed file into memory; got 12394rows\n"
     ]
    }
   ],
   "source": [
    "import momma_dragonn\n",
    "from momma_dragonn.data_loaders.pyfasta_data_loader import SingleStreamSeqOnly\n",
    "import numpy as np\n",
    "import gzip\n",
    "\n",
    "fasta_data_source = \"/mnt/data/annotations/by_organism/human/hg19.GRCh37/hg19.genome.fa\"\n",
    "positives_data_loader = SingleStreamSeqOnly(batch_size=50, bed_source=\"positives_not_in_small_valid_labels.gz\",\n",
    "                                  fasta_data_source=fasta_data_source,\n",
    "                                  rc_augment=False, randomize_after_pass=False, num_to_load_for_eval=None)\n",
    "positives_data = positives_data_loader.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_QFbAM_modelJson.json\t       record_18_model_u5eMJ_modelWeights.h5\r\n",
      "model_QFbAM_modelWeights.h5\t       record_19_model_h9WFI_modelJson.json\r\n",
      "model_UqOJX_modelJson.json\t       record_19_model_h9WFI_modelWeights.h5\r\n",
      "model_UqOJX_modelWeights.h5\t       record_1_model_v4VYz_modelJson.json\r\n",
      "record_10_model_audzA_modelJson.json   record_1_model_v4VYz_modelWeights.h5\r\n",
      "record_10_model_audzA_modelWeights.h5  record_2_model_IH83H_modelJson.json\r\n",
      "record_11_model_0XKud_modelJson.json   record_2_model_IH83H_modelWeights.h5\r\n",
      "record_11_model_0XKud_modelWeights.h5  record_3_model_0FT6i_modelJson.json\r\n",
      "record_12_model_rjGet_modelJson.json   record_3_model_0FT6i_modelWeights.h5\r\n",
      "record_12_model_rjGet_modelWeights.h5  record_4_model_Dvrnb_modelJson.json\r\n",
      "record_13_model_FXPOF_modelJson.json   record_4_model_Dvrnb_modelWeights.h5\r\n",
      "record_13_model_FXPOF_modelWeights.h5  record_5_model_1Q9Lp_modelJson.json\r\n",
      "record_14_model_g60lE_modelJson.json   record_5_model_1Q9Lp_modelWeights.h5\r\n",
      "record_14_model_g60lE_modelWeights.h5  record_6_model_svFYA_modelJson.json\r\n",
      "record_15_model_REDP7_modelJson.json   record_6_model_svFYA_modelWeights.h5\r\n",
      "record_15_model_REDP7_modelWeights.h5  record_7_model_2ObnU_modelJson.json\r\n",
      "record_16_model_tSI7v_modelJson.json   record_7_model_2ObnU_modelWeights.h5\r\n",
      "record_16_model_tSI7v_modelWeights.h5  record_8_model_qyto7_modelJson.json\r\n",
      "record_17_model_Fljbs_modelJson.json   record_8_model_qyto7_modelWeights.h5\r\n",
      "record_17_model_Fljbs_modelWeights.h5  record_9_model_ROCRa_modelJson.json\r\n",
      "record_18_model_u5eMJ_modelJson.json   record_9_model_ROCRa_modelWeights.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls model_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import deeplift\n",
    "from deeplift.conversion import kerasapi_conversion as kc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonlinear_mxts_mode is set to: DeepLIFT_GenomicsDefault\n",
      "For layer 2 the preceding linear layer is 0 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "For layer 6 the preceding linear layer is 4 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "For layer 10 the preceding linear layer is 8 of type Conv1D;\n",
      "In accordance with nonlinear_mxts_mode=DeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to Rescale\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "For layer 15 the preceding linear layer is 13 of type Dense;\n",
      "In accordance with nonlinear_mxts_modeDeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to RevealCancel\n",
      "For layer 19 the preceding linear layer is 17 of type Dense;\n",
      "In accordance with nonlinear_mxts_modeDeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to RevealCancel\n",
      "Heads-up: I assume sigmoid is the output layer, not an intermediate one; if it's an intermediate layer then please bug me and I will implement the grad func\n",
      "For layer 21 the preceding linear layer is 20 of type Dense;\n",
      "In accordance with nonlinear_mxts_modeDeepLIFT_GenomicsDefault we are setting the NonlinearMxtsMode to RevealCancel\n",
      "nonlinear_mxts_mode is set to: Rescale\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "Heads-up: I assume sigmoid is the output layer, not an intermediate one; if it's an intermediate layer then please bug me and I will implement the grad func\n"
     ]
    }
   ],
   "source": [
    "model_id = \"record_1_model_v4VYz\"\n",
    "model_json = \"model_files/\"+model_id+\"_modelJson.json\"\n",
    "model_weights = \"model_files/\"+model_id+\"_modelWeights.h5\"\n",
    "#model_json = \"model_files/model_UqOJX_modelJson.json\"\n",
    "#model_weights = \"model_files/model_UqOJX_modelWeights.h5\"\n",
    "deeplift_genomicsdefault_model =\\\n",
    "    kc.convert_model_from_saved_files(\n",
    "        json_file=model_json,\n",
    "        h5_file=model_weights,\n",
    "        nonlinear_mxts_mode=deeplift.layers.NonlinearMxtsMode.DeepLIFT_GenomicsDefault) \n",
    "deeplift_rescale_model =\\\n",
    "    kc.convert_model_from_saved_files(\n",
    "        json_file=model_json,\n",
    "        h5_file=model_weights,\n",
    "        nonlinear_mxts_mode=deeplift.layers.NonlinearMxtsMode.Rescale) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check that the model performs reasonably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#valid_data_loader = SingleStreamSeqOnly(batch_size=50, bed_source=\"small_valid_labels.gz\",\n",
    "#                                  fasta_data_source=fasta_data_source,\n",
    "#                                  rc_augment=False, randomize_after_pass=False, num_to_load_for_eval=None)\n",
    "#valid_data = valid_data_loader.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a basic investigation of GC fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mean_neg = np.mean(valid_data.X[valid_data.Y.squeeze()==0],axis=0)\n",
    "#mean_pos = np.mean(valid_data.X[valid_data.Y.squeeze()==1],axis=0)\n",
    "#print(\"Negatives ACGT frac\")\n",
    "#print(np.mean(valid_data.X[valid_data.Y.squeeze()==0],axis=(0,1)))\n",
    "#print(\"Positives ACGT frac\")\n",
    "#print(np.mean(valid_data.X[valid_data.Y.squeeze()==1],axis=(0,1)))\n",
    "#print(\"for negatives\")\n",
    "#plt.plot(range(1000),mean_neg[:,0]+mean_neg[:,3])\n",
    "#plt.plot(range(1000),mean_neg[:,1]+mean_neg[:,2])\n",
    "#plt.show()\n",
    "#print(\"for positives\")\n",
    "#plt.plot(range(1000),mean_pos[:,0]+mean_pos[:,3])\n",
    "#plt.plot(range(1000),mean_pos[:,1]+mean_pos[:,2])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_func = deeplift.util.compile_func(\n",
    "    inputs=[deeplift_genomicsdefault_model.get_layers()[0].get_activation_vars()],\n",
    "    outputs=deeplift_genomicsdefault_model.get_layers()[-2].get_activation_vars()[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#valid_preds = np.array(deeplift.util.run_function_in_batches(pred_func,\n",
    "#                            input_data_list=[valid_data.X],\n",
    "#                            batch_size=200,\n",
    "#                            progress_update=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "Done 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "unseen_positives_preds = np.array(deeplift.util.run_function_in_batches(pred_func,\n",
    "                            input_data_list=[positives_data.X],\n",
    "                            batch_size=200,\n",
    "                            progress_update=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "#print(roc_auc_score(y_true=valid_data.Y.squeeze(), y_score=np.array(valid_preds).squeeze()))\n",
    "#from matplotlib import pyplot as plt\n",
    "##histogram the predictions\n",
    "#sns.distplot(valid_preds[valid_data.Y.squeeze()==0],bins=20)\n",
    "#sns.distplot(valid_preds[valid_data.Y.squeeze()==1],bins=20)\n",
    "#sns.distplot(unseen_positives_preds,bins=20)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the deeplift, gradients and integrated gradients scoring functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions for dinuc shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deeplift import dinuc_shuffle\n",
    "\n",
    "argmax_to_letter = {0:'A', 1:'C', 2:'G', 3:'T'}\n",
    "def onehot_to_seq(onehot):\n",
    "    seq = \"\".join([argmax_to_letter[x] for x in np.argmax(onehot,axis=-1)])\n",
    "    return seq\n",
    "\n",
    "def one_hot_encode_along_channel_axis(sequence):\n",
    "    to_return = np.zeros((len(sequence),4), dtype=np.int8)\n",
    "    seq_to_one_hot_fill_in_array(zeros_array=to_return,\n",
    "                                 sequence=sequence, one_hot_axis=1)\n",
    "    return to_return\n",
    "\n",
    "def seq_to_one_hot_fill_in_array(zeros_array, sequence, one_hot_axis):\n",
    "    assert one_hot_axis==0 or one_hot_axis==1\n",
    "    if (one_hot_axis==0):\n",
    "        assert zeros_array.shape[1] == len(sequence)\n",
    "    elif (one_hot_axis==1): \n",
    "        assert zeros_array.shape[0] == len(sequence)\n",
    "    #will mutate zeros_array\n",
    "    for (i,char) in enumerate(sequence):\n",
    "        if (char==\"A\" or char==\"a\"):\n",
    "            char_idx = 0\n",
    "        elif (char==\"C\" or char==\"c\"):\n",
    "            char_idx = 1\n",
    "        elif (char==\"G\" or char==\"g\"):\n",
    "            char_idx = 2\n",
    "        elif (char==\"T\" or char==\"t\"):\n",
    "            char_idx = 3\n",
    "        elif (char==\"N\" or char==\"n\"):\n",
    "            continue #leave that pos as all 0's\n",
    "        else:\n",
    "            raise RuntimeError(\"Unsupported character: \"+str(char))\n",
    "        if (one_hot_axis==0):\n",
    "            zeros_array[char_idx,i] = 1\n",
    "        elif (one_hot_axis==1):\n",
    "            zeros_array[i,char_idx] = 1\n",
    "            \n",
    "positives_seqs = [onehot_to_seq(x) for x in positives_data.X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at prediction with flat references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction under all zero input [-14.88747]\n",
      "Prediction under avg pos input [116.84889]\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction under all zero input\",pred_func([np.zeros((1,1000,4))]))\n",
    "avgpos_gcref = np.mean(positives_data.X, axis=0, keepdims=True)\n",
    "print(\"Prediction under avg pos input\", pred_func([avgpos_gcref]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the various scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "grad = tf.gradients(ys=deeplift_genomicsdefault_model.get_layers()[-2].get_activation_vars(),\n",
    "                    xs=deeplift_genomicsdefault_model.get_layers()[0].get_activation_vars())[0]\n",
    "unbatched_grad_func = deeplift.util.compile_func(\n",
    "                        inputs=[deeplift_genomicsdefault_model.get_layers()[0].get_activation_vars()],\n",
    "                        outputs=grad)\n",
    "\n",
    "def list_wrapper(func):\n",
    "    def wrapped_func(input_data_list, **kwargs):\n",
    "        if (isinstance(input_data_list, list)):\n",
    "            remove_list_on_return=False\n",
    "        else:\n",
    "            remove_list_on_return=True\n",
    "            input_data_list = [input_data_list]\n",
    "        to_return = func(input_data_list=input_data_list,\n",
    "                         **kwargs)\n",
    "        return to_return\n",
    "    return wrapped_func\n",
    "\n",
    "@list_wrapper\n",
    "def grad_func(input_data_list, input_references_list, task_idx, **kwargs):\n",
    "    assert len(input_data_list)==1\n",
    "    to_return = np.array(deeplift.util.run_function_in_batches(\n",
    "                    unbatched_grad_func,\n",
    "                    input_data_list=input_data_list,\n",
    "                    **kwargs))\n",
    "    return to_return\n",
    "\n",
    "def empty_ism_buffer(results_arr,\n",
    "                     input_data_onehot,\n",
    "                     perturbed_inputs_preds,\n",
    "                     perturbed_inputs_info):\n",
    "    for perturbed_input_pred,perturbed_input_info\\\n",
    "        in zip(perturbed_inputs_preds, perturbed_inputs_info):\n",
    "        example_idx = perturbed_input_info[0]\n",
    "        if (perturbed_input_info[1]==\"original\"):\n",
    "            results_arr[example_idx] +=\\\n",
    "                (perturbed_input_pred*input_data_onehot[example_idx])\n",
    "        else:\n",
    "            pos_idx,base_idx = perturbed_input_info[1]\n",
    "            results_arr[example_idx,pos_idx,base_idx] = perturbed_input_pred\n",
    "\n",
    "def make_ism_func(prediction_func,\n",
    "                  flank_around_middle_to_perturb,\n",
    "                  batch_size=200):\n",
    "    @list_wrapper\n",
    "    def ism_func(input_data_list, progress_update=10000, **kwargs):\n",
    "        assert len(input_data_list)==1\n",
    "        input_data_onehot=input_data_list[0]\n",
    "        \n",
    "        results_arr = np.zeros_like(input_data_onehot).astype(\"float64\")\n",
    "        \n",
    "        perturbed_inputs_info = []\n",
    "        perturbed_onehot_seqs = []\n",
    "        perturbed_inputs_preds = []\n",
    "        num_done = 0\n",
    "        for i,onehot_seq in enumerate(input_data_onehot):\n",
    "            perturbed_onehot_seqs.append(onehot_seq)\n",
    "            perturbed_inputs_info.append((i,\"original\"))\n",
    "            for pos in range(int(len(onehot_seq)/2)-flank_around_middle_to_perturb,\n",
    "                             int(len(onehot_seq)/2)+flank_around_middle_to_perturb):\n",
    "                for base_idx in range(4):\n",
    "                    if onehot_seq[pos,base_idx]==0:\n",
    "                        assert len(onehot_seq.shape)==2\n",
    "                        new_onehot = np.zeros_like(onehot_seq) + onehot_seq\n",
    "                        new_onehot[pos,:] = 0\n",
    "                        new_onehot[pos,base_idx] = 1\n",
    "                        perturbed_onehot_seqs.append(new_onehot)\n",
    "                        perturbed_inputs_info.append((i,(pos,base_idx)))\n",
    "                        num_done += 1\n",
    "                        if ((progress_update is not None)\n",
    "                            and num_done%progress_update==0):\n",
    "                            print(\"Done\",num_done)\n",
    "                        if (len(perturbed_inputs_info)>=batch_size):\n",
    "                            empty_ism_buffer(\n",
    "                                 results_arr=results_arr,\n",
    "                                 input_data_onehot=input_data_onehot,\n",
    "                                 perturbed_inputs_preds=\n",
    "                                  prediction_func([perturbed_onehot_seqs]),\n",
    "                                 perturbed_inputs_info=perturbed_inputs_info)\n",
    "                            perturbed_inputs_info = []\n",
    "                            perturbed_onehot_seqs = []\n",
    "        if (len(perturbed_inputs_info)>0):\n",
    "            empty_ism_buffer(\n",
    "                 results_arr=results_arr,\n",
    "                 input_data_onehot=input_data_onehot,\n",
    "                 perturbed_inputs_preds=\n",
    "                  prediction_func([perturbed_onehot_seqs]),\n",
    "                 perturbed_inputs_info=perturbed_inputs_info)\n",
    "        perturbed_inputs_info = []\n",
    "        perturbed_onehot_seqs = []\n",
    "        results_arr = results_arr - np.mean(results_arr,axis=-1)[:,:,None]\n",
    "        return input_data_onehot*results_arr\n",
    "    return ism_func\n",
    "\n",
    "@list_wrapper\n",
    "def grad_times_inp_func(input_data_list, **kwargs):\n",
    "    assert len(input_data_list)==1\n",
    "    print(\"Ignoring reference for grad*input\")\n",
    "    grads = grad_func(input_data_list=input_data_list, **kwargs)\n",
    "    return grads*input_data_list[0]\n",
    "\n",
    "def get_project_onto_bases_func(func):\n",
    "    @list_wrapper\n",
    "    def project_onto_bases(input_data_list, **kwargs):\n",
    "        assert len(input_data_list)==1\n",
    "        to_return = func(input_data_list=input_data_list, **kwargs)\n",
    "        return input_data_list[0]*np.sum(to_return,axis=-1)[:,:,None]\n",
    "    return project_onto_bases\n",
    "\n",
    "ism_func = make_ism_func(prediction_func=pred_func,\n",
    "                         flank_around_middle_to_perturb=150,\n",
    "                         batch_size=200)\n",
    "\n",
    "intgrad10_func = get_project_onto_bases_func(deeplift.util.get_integrated_gradients_function(\n",
    "                    gradient_computation_function=grad_func, \n",
    "                    num_intervals=10))\n",
    "intgrad20_func = get_project_onto_bases_func(deeplift.util.get_integrated_gradients_function(\n",
    "                    gradient_computation_function=grad_func, \n",
    "                    num_intervals=20))\n",
    "\n",
    "deeplift_genomicsdefault_contribs_func = get_project_onto_bases_func(\n",
    "    deeplift_genomicsdefault_model.get_target_contribs_func(find_scores_layer_idx=0))\n",
    "deeplift_rescale_contribs_func = get_project_onto_bases_func(\n",
    "    deeplift_rescale_model.get_target_contribs_func(find_scores_layer_idx=0))\n",
    "\n",
    "deeplift_genomicsdefault_dinucshuff_scoringfunc = deeplift.util.get_shuffle_seq_ref_function(\n",
    "    score_computation_function=deeplift_genomicsdefault_contribs_func,\n",
    "    shuffle_func=deeplift.dinuc_shuffle.dinuc_shuffle,\n",
    "    one_hot_func=lambda x: np.array([one_hot_encode_along_channel_axis(y) for y in x]))\n",
    "\n",
    "deeplift_rescale_dinucshuff_scoringfunc = deeplift.util.get_shuffle_seq_ref_function(\n",
    "    score_computation_function=deeplift_rescale_contribs_func,\n",
    "    shuffle_func=deeplift.dinuc_shuffle.dinuc_shuffle,\n",
    "    one_hot_func=lambda x: np.array([one_hot_encode_along_channel_axis(y) for y in x]))\n",
    "\n",
    "intgrad10_dinucshuff_scoringfunc = deeplift.util.get_shuffle_seq_ref_function(\n",
    "    score_computation_function=intgrad10_func,\n",
    "    shuffle_func=deeplift.dinuc_shuffle.dinuc_shuffle,\n",
    "    one_hot_func=lambda x: np.array([one_hot_encode_along_channel_axis(y) for y in x]))\n",
    "intgrad20_dinucshuff_scoringfunc = deeplift.util.get_shuffle_seq_ref_function(\n",
    "    score_computation_function=intgrad20_func,\n",
    "    shuffle_func=deeplift.dinuc_shuffle.dinuc_shuffle,\n",
    "    one_hot_func=lambda x: np.array([one_hot_encode_along_channel_axis(y) for y in x]))\n",
    "    \n",
    "method_name_to_scoring_func = {\n",
    "                 'ism': ism_func,\n",
    "                 'grad_times_inp': grad_times_inp_func,\n",
    "                 'integrated_grad10': intgrad10_func,\n",
    "                 'integrated_grad20': intgrad20_func,\n",
    "                 'deeplift_genomicsdefault': deeplift_genomicsdefault_contribs_func,\n",
    "                 'deeplift_rescale': deeplift_rescale_contribs_func,\n",
    "                 'deeplift_genomicsdefault_dinucshuff': deeplift_genomicsdefault_dinucshuff_scoringfunc,\n",
    "                 'deeplift_rescale_dinucshuff': deeplift_rescale_dinucshuff_scoringfunc,\n",
    "                 'integrated_grad10_dinucshuff': intgrad10_dinucshuff_scoringfunc,\n",
    "                 'integrated_grad20_dinucshuff': intgrad20_dinucshuff_scoringfunc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute scores with different references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12394\n"
     ]
    }
   ],
   "source": [
    "sorted_prediction_indices = [x[0] for x in sorted(enumerate(unseen_positives_preds),\n",
    "                             key=lambda x: -x[1])]\n",
    "print(len(sorted_prediction_indices))\n",
    "subset_indices = sorted_prediction_indices[::10]\n",
    "positives_X_subset_preds = np.array([unseen_positives_preds[i] for i in subset_indices])\n",
    "positives_X_subset = np.array([positives_data.X[i] for i in subset_indices])\n",
    "positives_X_subset_seqs = [positives_seqs[i] for i in subset_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute scores on unseen positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores to imp_scores_record_1_model_v4VYz.h5\n",
      "grad_times_inp\n",
      "flatref\n",
      "Ignoring reference for grad*input\n",
      "Done 0\n",
      "Done 1000\n",
      "Time taken for grad_times_inp flatref 1.15842008591\n",
      "avgposref\n",
      "Ignoring reference for grad*input\n",
      "Done 0\n",
      "Done 1000\n",
      "Time taken for grad_times_inp avgposref 1.09515690804\n",
      "integrated_grad10\n",
      "flatref\n",
      "Done 0\n",
      "Done 1000\n",
      "Done 2000\n",
      "Done 3000\n",
      "Done 4000\n",
      "Done 5000\n",
      "Done 6000\n",
      "Done 7000\n",
      "Done 8000\n",
      "Done 9000\n",
      "Done 10000\n",
      "Done 11000\n",
      "Done 12000\n",
      "Time taken for integrated_grad10 flatref 11.1866791248\n",
      "avgposref\n",
      "Done 0\n",
      "Done 1000\n",
      "Done 2000\n",
      "Done 3000\n",
      "Done 4000\n",
      "Done 5000\n",
      "Done 6000\n",
      "Done 7000\n",
      "Done 8000\n",
      "Done 9000\n",
      "Done 10000\n",
      "Done 11000\n",
      "Done 12000\n",
      "Time taken for integrated_grad10 avgposref 11.0978450775\n",
      "integrated_grad20\n",
      "flatref\n",
      "Done 0\n",
      "Done 1000\n",
      "Done 2000\n",
      "Done 3000\n",
      "Done 4000\n",
      "Done 5000\n",
      "Done 6000\n",
      "Done 7000\n",
      "Done 8000\n",
      "Done 9000\n",
      "Done 10000\n",
      "Done 11000\n",
      "Done 12000\n",
      "Done 13000\n",
      "Done 14000\n",
      "Done 15000\n",
      "Done 16000\n",
      "Done 17000\n",
      "Done 18000\n",
      "Done 19000\n",
      "Done 20000\n",
      "Done 21000\n",
      "Done 22000\n",
      "Done 23000\n",
      "Done 24000\n",
      "Time taken for integrated_grad20 flatref 22.0031769276\n",
      "avgposref\n",
      "Done 0\n",
      "Done 1000\n",
      "Done 2000\n",
      "Done 3000\n",
      "Done 4000\n",
      "Done 5000\n",
      "Done 6000\n",
      "Done 7000\n",
      "Done 8000\n",
      "Done 9000\n",
      "Done 10000\n",
      "Done 11000\n",
      "Done 12000\n",
      "Done 13000\n",
      "Done 14000\n",
      "Done 15000\n",
      "Done 16000\n",
      "Done 17000\n",
      "Done 18000\n",
      "Done 19000\n",
      "Done 20000\n",
      "Done 21000\n",
      "Done 22000\n",
      "Done 23000\n",
      "Done 24000\n",
      "Time taken for integrated_grad20 avgposref 21.7269890308\n",
      "deeplift_rescale\n",
      "flatref\n",
      "Done 0\n",
      "Done 1000\n",
      "Time taken for deeplift_rescale flatref 3.66964101791\n",
      "avgposref\n",
      "Done 0\n",
      "Done 1000\n",
      "Time taken for deeplift_rescale avgposref 3.77719211578\n",
      "deeplift_genomicsdefault\n",
      "flatref\n",
      "Done 0\n",
      "Done 1000\n",
      "Time taken for deeplift_genomicsdefault flatref 3.8569278717\n",
      "avgposref\n",
      "Done 0\n",
      "Done 1000\n",
      "Time taken for deeplift_genomicsdefault avgposref 3.91066503525\n",
      "deeplift_rescale_dinucshuff\n",
      "1000 reference seqs generated\n",
      "2000 reference seqs generated\n",
      "3000 reference seqs generated\n",
      "4000 reference seqs generated\n",
      "5000 reference seqs generated\n",
      "6000 reference seqs generated\n",
      "7000 reference seqs generated\n",
      "8000 reference seqs generated\n",
      "9000 reference seqs generated\n",
      "10000 reference seqs generated\n",
      "11000 reference seqs generated\n",
      "12000 reference seqs generated\n",
      "One hot encoding sequences...\n",
      "One hot encoding done...\n",
      "Done 0\n",
      "Done 1000\n",
      "Done 2000\n",
      "Done 3000\n",
      "Done 4000\n",
      "Done 5000\n",
      "Done 6000\n",
      "Done 7000\n",
      "Done 8000\n",
      "Done 9000\n",
      "Done 10000\n",
      "Done 11000\n",
      "Done 12000\n",
      "Time taken for deeplift_rescale_dinucshuff 39.4570419788\n",
      "deeplift_genomicsdefault_dinucshuff\n",
      "1000 reference seqs generated\n",
      "2000 reference seqs generated\n",
      "3000 reference seqs generated\n",
      "4000 reference seqs generated\n",
      "5000 reference seqs generated\n",
      "6000 reference seqs generated\n",
      "7000 reference seqs generated\n",
      "8000 reference seqs generated\n",
      "9000 reference seqs generated\n",
      "10000 reference seqs generated\n",
      "11000 reference seqs generated\n",
      "12000 reference seqs generated\n",
      "One hot encoding sequences...\n",
      "One hot encoding done...\n",
      "Done 0\n",
      "Done 1000\n",
      "Done 2000\n",
      "Done 3000\n",
      "Done 4000\n",
      "Done 5000\n",
      "Done 6000\n",
      "Done 7000\n",
      "Done 8000\n",
      "Done 9000\n",
      "Done 10000\n",
      "Done 11000\n",
      "Done 12000\n",
      "Time taken for deeplift_genomicsdefault_dinucshuff 40.3178358078\n",
      "integrated_grad10_dinucshuff\n",
      "1000 reference seqs generated\n",
      "2000 reference seqs generated\n",
      "3000 reference seqs generated\n",
      "4000 reference seqs generated\n",
      "5000 reference seqs generated\n",
      "6000 reference seqs generated\n",
      "7000 reference seqs generated\n",
      "8000 reference seqs generated\n",
      "9000 reference seqs generated\n",
      "10000 reference seqs generated\n",
      "11000 reference seqs generated\n",
      "12000 reference seqs generated\n",
      "One hot encoding sequences...\n",
      "One hot encoding done...\n",
      "Done 0\n",
      "Done 1000\n",
      "Done 2000\n",
      "Done 3000\n",
      "Done 4000\n",
      "Done 5000\n",
      "Done 6000\n",
      "Done 7000\n",
      "Done 8000\n",
      "Done 9000\n",
      "Done 10000\n",
      "Done 11000\n",
      "Done 12000\n",
      "Done 13000\n",
      "Done 14000\n",
      "Done 15000\n",
      "Done 16000\n",
      "Done 17000\n",
      "Done 18000\n",
      "Done 19000\n",
      "Done 20000\n",
      "Done 21000\n",
      "Done 22000\n",
      "Done 23000\n",
      "Done 24000\n",
      "Done 25000\n",
      "Done 26000\n",
      "Done 27000\n",
      "Done 28000\n",
      "Done 29000\n",
      "Done 30000\n",
      "Done 31000\n",
      "Done 32000\n",
      "Done 33000\n",
      "Done 34000\n",
      "Done 35000\n",
      "Done 36000\n",
      "Done 37000\n",
      "Done 38000\n",
      "Done 39000\n",
      "Done 40000\n",
      "Done 41000\n",
      "Done 42000\n",
      "Done 43000\n",
      "Done 44000\n",
      "Done 45000\n",
      "Done 46000\n",
      "Done 47000\n",
      "Done 48000\n",
      "Done 49000\n",
      "Done 50000\n",
      "Done 51000\n",
      "Done 52000\n",
      "Done 53000\n",
      "Done 54000\n",
      "Done 55000\n",
      "Done 56000\n",
      "Done 57000\n",
      "Done 58000\n",
      "Done 59000\n",
      "Done 60000\n",
      "Done 61000\n",
      "Done 62000\n",
      "Done 63000\n",
      "Done 64000\n",
      "Done 65000\n",
      "Done 66000\n",
      "Done 67000\n",
      "Done 68000\n",
      "Done 69000\n",
      "Done 70000\n",
      "Done 71000\n",
      "Done 72000\n",
      "Done 73000\n",
      "Done 74000\n",
      "Done 75000\n",
      "Done 76000\n",
      "Done 77000\n",
      "Done 78000\n",
      "Done 79000\n",
      "Done 80000\n",
      "Done 81000\n",
      "Done 82000\n",
      "Done 83000\n",
      "Done 84000\n",
      "Done 85000\n",
      "Done 86000\n",
      "Done 87000\n",
      "Done 88000\n",
      "Done 89000\n",
      "Done 90000\n",
      "Done 91000\n",
      "Done 92000\n",
      "Done 93000\n",
      "Done 94000\n",
      "Done 95000\n",
      "Done 96000\n",
      "Done 97000\n",
      "Done 98000\n",
      "Done 99000\n",
      "Done 100000\n",
      "Done 101000\n",
      "Done 102000\n",
      "Done 103000\n",
      "Done 104000\n",
      "Done 105000\n",
      "Done 106000\n",
      "Done 107000\n",
      "Done 108000\n",
      "Done 109000\n",
      "Done 110000\n",
      "Done 111000\n",
      "Done 112000\n",
      "Done 113000\n",
      "Done 114000\n",
      "Done 115000\n",
      "Done 116000\n",
      "Done 117000\n",
      "Done 118000\n",
      "Done 119000\n",
      "Done 120000\n",
      "Done 121000\n",
      "Done 122000\n",
      "Done 123000\n",
      "Time taken for integrated_grad10_dinucshuff 91.6728029251\n",
      "integrated_grad20_dinucshuff\n",
      "1000 reference seqs generated\n",
      "2000 reference seqs generated\n",
      "3000 reference seqs generated\n",
      "4000 reference seqs generated\n",
      "5000 reference seqs generated\n",
      "6000 reference seqs generated\n",
      "7000 reference seqs generated\n",
      "8000 reference seqs generated\n",
      "9000 reference seqs generated\n",
      "10000 reference seqs generated\n",
      "11000 reference seqs generated\n",
      "12000 reference seqs generated\n",
      "One hot encoding sequences...\n",
      "One hot encoding done...\n",
      "Done 0\n",
      "Done 1000\n",
      "Done 2000\n",
      "Done 3000\n",
      "Done 4000\n",
      "Done 5000\n",
      "Done 6000\n",
      "Done 7000\n",
      "Done 8000\n",
      "Done 9000\n",
      "Done 10000\n",
      "Done 11000\n",
      "Done 12000\n",
      "Done 13000\n",
      "Done 14000\n",
      "Done 15000\n",
      "Done 16000\n",
      "Done 17000\n",
      "Done 18000\n",
      "Done 19000\n",
      "Done 20000\n",
      "Done 21000\n",
      "Done 22000\n",
      "Done 23000\n",
      "Done 24000\n",
      "Done 25000\n",
      "Done 26000\n",
      "Done 27000\n",
      "Done 28000\n",
      "Done 29000\n",
      "Done 30000\n",
      "Done 31000\n",
      "Done 32000\n",
      "Done 33000\n",
      "Done 34000\n",
      "Done 35000\n",
      "Done 36000\n",
      "Done 37000\n",
      "Done 38000\n",
      "Done 39000\n",
      "Done 40000\n",
      "Done 41000\n",
      "Done 42000\n",
      "Done 43000\n",
      "Done 44000\n",
      "Done 45000\n",
      "Done 46000\n",
      "Done 47000\n",
      "Done 48000\n",
      "Done 49000\n",
      "Done 50000\n",
      "Done 51000\n",
      "Done 52000\n",
      "Done 53000\n",
      "Done 54000\n",
      "Done 55000\n",
      "Done 56000\n",
      "Done 57000\n",
      "Done 58000\n",
      "Done 59000\n",
      "Done 60000\n",
      "Done 61000\n",
      "Done 62000\n",
      "Done 63000\n",
      "Done 64000\n",
      "Done 65000\n",
      "Done 66000\n",
      "Done 67000\n",
      "Done 68000\n",
      "Done 69000\n",
      "Done 70000\n",
      "Done 71000\n",
      "Done 72000\n",
      "Done 73000\n",
      "Done 74000\n",
      "Done 75000\n",
      "Done 76000\n",
      "Done 77000\n",
      "Done 78000\n",
      "Done 79000\n",
      "Done 80000\n",
      "Done 81000\n",
      "Done 82000\n",
      "Done 83000\n",
      "Done 84000\n",
      "Done 85000\n",
      "Done 86000\n",
      "Done 87000\n",
      "Done 88000\n",
      "Done 89000\n",
      "Done 90000\n",
      "Done 91000\n",
      "Done 92000\n",
      "Done 93000\n",
      "Done 94000\n",
      "Done 95000\n",
      "Done 96000\n",
      "Done 97000\n",
      "Done 98000\n",
      "Done 99000\n",
      "Done 100000\n",
      "Done 101000\n",
      "Done 102000\n",
      "Done 103000\n",
      "Done 104000\n",
      "Done 105000\n",
      "Done 106000\n",
      "Done 107000\n",
      "Done 108000\n",
      "Done 109000\n",
      "Done 110000\n",
      "Done 111000\n",
      "Done 112000\n",
      "Done 113000\n",
      "Done 114000\n",
      "Done 115000\n",
      "Done 116000\n",
      "Done 117000\n",
      "Done 118000\n",
      "Done 119000\n",
      "Done 120000\n",
      "Done 121000\n",
      "Done 122000\n",
      "Done 123000\n",
      "Done 124000\n",
      "Done 125000\n",
      "Done 126000\n",
      "Done 127000\n",
      "Done 128000\n",
      "Done 129000\n",
      "Done 130000\n",
      "Done 131000\n",
      "Done 132000\n",
      "Done 133000\n",
      "Done 134000\n",
      "Done 135000\n",
      "Done 136000\n",
      "Done 137000\n",
      "Done 138000\n",
      "Done 139000\n",
      "Done 140000\n",
      "Done 141000\n",
      "Done 142000\n",
      "Done 143000\n",
      "Done 144000\n",
      "Done 145000\n",
      "Done 146000\n",
      "Done 147000\n",
      "Done 148000\n",
      "Done 149000\n",
      "Done 150000\n",
      "Done 151000\n",
      "Done 152000\n",
      "Done 153000\n",
      "Done 154000\n",
      "Done 155000\n",
      "Done 156000\n",
      "Done 157000\n",
      "Done 158000\n",
      "Done 159000\n",
      "Done 160000\n",
      "Done 161000\n",
      "Done 162000\n",
      "Done 163000\n",
      "Done 164000\n",
      "Done 165000\n",
      "Done 166000\n",
      "Done 167000\n",
      "Done 168000\n",
      "Done 169000\n",
      "Done 170000\n",
      "Done 171000\n",
      "Done 172000\n",
      "Done 173000\n",
      "Done 174000\n",
      "Done 175000\n",
      "Done 176000\n",
      "Done 177000\n",
      "Done 178000\n",
      "Done 179000\n",
      "Done 180000\n",
      "Done 181000\n",
      "Done 182000\n",
      "Done 183000\n",
      "Done 184000\n",
      "Done 185000\n",
      "Done 186000\n",
      "Done 187000\n",
      "Done 188000\n",
      "Done 189000\n",
      "Done 190000\n",
      "Done 191000\n",
      "Done 192000\n",
      "Done 193000\n",
      "Done 194000\n",
      "Done 195000\n",
      "Done 196000\n",
      "Done 197000\n",
      "Done 198000\n",
      "Done 199000\n",
      "Done 200000\n",
      "Done 201000\n",
      "Done 202000\n",
      "Done 203000\n",
      "Done 204000\n",
      "Done 205000\n",
      "Done 206000\n",
      "Done 207000\n",
      "Done 208000\n",
      "Done 209000\n",
      "Done 210000\n",
      "Done 211000\n",
      "Done 212000\n",
      "Done 213000\n",
      "Done 214000\n",
      "Done 215000\n",
      "Done 216000\n",
      "Done 217000\n",
      "Done 218000\n",
      "Done 219000\n",
      "Done 220000\n",
      "Done 221000\n",
      "Done 222000\n",
      "Done 223000\n",
      "Done 224000\n",
      "Done 225000\n",
      "Done 226000\n",
      "Done 227000\n",
      "Done 228000\n",
      "Done 229000\n",
      "Done 230000\n",
      "Done 231000\n",
      "Done 232000\n",
      "Done 233000\n",
      "Done 234000\n",
      "Done 235000\n",
      "Done 236000\n",
      "Done 237000\n",
      "Done 238000\n",
      "Done 239000\n",
      "Done 240000\n",
      "Done 241000\n",
      "Done 242000\n",
      "Done 243000\n",
      "Done 244000\n",
      "Done 245000\n",
      "Done 246000\n",
      "Done 247000\n",
      "Time taken for integrated_grad20_dinucshuff 163.119200945\n",
      "ism\n",
      "Done 10000\n",
      "Done 20000\n",
      "Done 30000\n",
      "Done 40000\n",
      "Done 50000\n",
      "Done 60000\n",
      "Done 70000\n",
      "Done 80000\n",
      "Done 90000\n",
      "Done 100000\n",
      "Done 110000\n",
      "Done 120000\n",
      "Done 130000\n",
      "Done 140000\n",
      "Done 150000\n",
      "Done 160000\n",
      "Done 170000\n",
      "Done 180000\n",
      "Done 190000\n",
      "Done 200000\n",
      "Done 210000\n",
      "Done 220000\n",
      "Done 230000\n",
      "Done 240000\n",
      "Done 250000\n",
      "Done 260000\n",
      "Done 270000\n",
      "Done 280000\n",
      "Done 290000\n",
      "Done 300000\n",
      "Done 310000\n",
      "Done 320000\n",
      "Done 330000\n",
      "Done 340000\n",
      "Done 350000\n",
      "Done 360000\n",
      "Done 370000\n",
      "Done 380000\n",
      "Done 390000\n",
      "Done 400000\n",
      "Done 410000\n",
      "Done 420000\n",
      "Done 430000\n",
      "Done 440000\n",
      "Done 450000\n",
      "Done 460000\n",
      "Done 470000\n",
      "Done 480000\n",
      "Done 490000\n",
      "Done 500000\n",
      "Done 510000\n",
      "Done 520000\n",
      "Done 530000\n",
      "Done 540000\n",
      "Done 550000\n",
      "Done 560000\n",
      "Done 570000\n",
      "Done"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import time\n",
    "\n",
    "method_to_scores_flatref = {}\n",
    "method_to_scores_avgposref = {}\n",
    "method_to_scores_shuffref = {}\n",
    "method_to_ism_score = {}\n",
    "\n",
    "scores_file_name = \"imp_scores_\"+model_id+\".h5\"\n",
    "print(\"Saving scores to\",scores_file_name)\n",
    "#!rm $scores_file_name\n",
    "file_to_save_in = h5py.File(scores_file_name)\n",
    "file_to_save_in.create_dataset(\"onehot\",data=positives_X_subset)\n",
    "\n",
    "for method_name in ['grad_times_inp',\n",
    "                    'integrated_grad10',\n",
    "                    'integrated_grad20',\n",
    "                    'deeplift_rescale',\n",
    "                    'deeplift_genomicsdefault']:\n",
    "    print(method_name)\n",
    "    print(\"flatref\")\n",
    "    scoring_func = method_name_to_scoring_func[method_name]\n",
    "    start = time.time()\n",
    "    scores_flatref = np.array(scoring_func(input_data_list=[positives_X_subset],\n",
    "                          input_references_list=[np.zeros_like(positives_X_subset)],\n",
    "                          task_idx=0, batch_size=10, progress_update=1000))\n",
    "    print(\"Time taken for\",method_name,\"flatref\",time.time()-start)\n",
    "    file_to_save_in.create_dataset(\"scores_\"+method_name+\"_flatref\",\n",
    "                                   data=np.sum(scores_flatref,axis=-1))\n",
    "    print(\"avgposref\")\n",
    "    start = time.time()\n",
    "    scores_avgposref = np.array(scoring_func(input_data_list=[positives_X_subset],\n",
    "                          input_references_list=[np.array([avgpos_gcref[0] for x in positives_X_subset])],\n",
    "                          task_idx=0, batch_size=10, progress_update=1000))\n",
    "    print(\"Time taken for\",method_name,\"avgposref\",time.time()-start)\n",
    "    file_to_save_in.create_dataset(\"scores_\"+method_name+\"_avgposref\",\n",
    "                                   data=np.sum(scores_avgposref,axis=-1))\n",
    "    method_to_scores_flatref[method_name] = scores_flatref\n",
    "    method_to_scores_avgposref[method_name] = scores_avgposref\n",
    "\n",
    "for method_name in ['deeplift_rescale_dinucshuff',\n",
    "                    'deeplift_genomicsdefault_dinucshuff',\n",
    "                    'integrated_grad10_dinucshuff',\n",
    "                    'integrated_grad20_dinucshuff']:\n",
    "    print(method_name)\n",
    "    start = time.time()\n",
    "    scores_shuffref = method_name_to_scoring_func[method_name](\n",
    "        task_idx=0,\n",
    "        input_data_sequences=positives_X_subset_seqs,\n",
    "        num_refs_per_seq=10,\n",
    "        batch_size=200, seed=1,\n",
    "        progress_update=1000)\n",
    "    print(\"Time taken for\",method_name,time.time()-start)\n",
    "    file_to_save_in.create_dataset(\"scores_\"+method_name,data=np.sum(scores_shuffref,axis=-1))\n",
    "    method_to_scores_shuffref[method_name] = scores_shuffref\n",
    "\n",
    "for method_name in ['ism']:\n",
    "    print(method_name)\n",
    "    start = time.time()\n",
    "    scoring_func = method_name_to_scoring_func[method_name]\n",
    "    scores_ism = np.array(scoring_func(input_data_list=[positives_X_subset],\n",
    "                                       progress_update=10000))\n",
    "    print(\"Time taken for\",method_name,time.time()-start)\n",
    "    file_to_save_in.create_dataset(\"scores_\"+method_name,data=np.sum(scores_ism,axis=-1))\n",
    "    method_to_ism_score[method_name] = scores_ism\n",
    "\n",
    "file_to_save_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from deeplift.visualization import viz_sequence\n",
    "\n",
    "start_range = 350\n",
    "end_range = 650\n",
    "\n",
    "for i in range(1,len(positives_X_subset_preds),int(len(positives_X_subset_preds)/10)):\n",
    "    print(i)\n",
    "    print(subset_indices[i])\n",
    "    print(positives_X_subset_preds[i])\n",
    "    \n",
    "    for method_name in ['ism']:\n",
    "        print(method_name)\n",
    "        viz_sequence.plot_weights(\n",
    "            method_to_ism_score[method_name][i,start_range:end_range],\n",
    "            subticks_frequency=20)\n",
    "    \n",
    "    for method_name in ['integrated10_grad_dinucshuff',\n",
    "                        'integrated20_grad_dinucshuff',\n",
    "                        'deeplift_rescale_dinucshuff',\n",
    "                        'deeplift_genomicsdefault_dinucshuff']:\n",
    "        print(method_name)\n",
    "        viz_sequence.plot_weights(\n",
    "            method_to_scores_shuffref[method_name][i,start_range:end_range],\n",
    "            subticks_frequency=20)\n",
    "    \n",
    "    for method_name in ['grad_times_inp',\n",
    "                        'integrated_grad10',\n",
    "                        'integrated_grad20',\n",
    "                        'deeplift_rescale',\n",
    "                        'deeplift_genomicsdefault']:\n",
    "        print(method_name)\n",
    "        print(\"flat ref\")\n",
    "        viz_sequence.plot_weights(\n",
    "            method_to_scores_flatref[method_name][i,start_range:end_range],\n",
    "            subticks_frequency=20)\n",
    "        if (method_name != 'grad_times_inp'):\n",
    "            print(\"gc ref\")\n",
    "            viz_sequence.plot_weights(\n",
    "                method_to_scores_avgposref[method_name][i,start_range:end_range],\n",
    "                subticks_frequency=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore preds on dinuc shuffled seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dinuc_shuff_positives_seqs = [deeplift.dinuc_shuffle.dinuc_shuffle(x) for x in positives_seqs]\n",
    "dinuc_shuff_positives_onehot = np.array([one_hot_encode_along_channel_axis(x) for x in dinuc_shuff_positives_seqs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get preds on dinuc shuffled sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "Done 10000\n",
      "Done 0\n",
      "Done 10000\n"
     ]
    }
   ],
   "source": [
    "dinuc_shuff_positives_preds = np.array(deeplift.util.run_function_in_batches(pred_func,\n",
    "                            input_data_list=[dinuc_shuff_positives_onehot],\n",
    "                            batch_size=200,\n",
    "                            progress_update=10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get preds on randomly shuffled sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n",
      "Done 10000\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def random_shuff_seq(seq):\n",
    "    arr = [x for x in seq]\n",
    "    shuffle(arr)\n",
    "    return \"\".join(arr)\n",
    "\n",
    "random_shuff_positives_seqs = [random_shuff_seq(x) for x in positives_seqs]\n",
    "random_shuff_positives_onehot = np.array([one_hot_encode_along_channel_axis(x) for x in random_shuff_positives_seqs])\n",
    "random_shuff_positives_preds = np.array(deeplift.util.run_function_in_batches(pred_func,\n",
    "                            input_data_list=[random_shuff_positives_onehot],\n",
    "                            batch_size=200,\n",
    "                            progress_update=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9070251479705824\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4bec646b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y_true=valid_data.Y.squeeze(), y_score=np.array(valid_preds).squeeze()))\n",
    "from matplotlib import pyplot as plt\n",
    "#histogram the predictions\n",
    "sns.distplot(valid_preds[valid_data.Y.squeeze()==0],bins=20)\n",
    "#sns.distplot(valid_preds[valid_data.Y.squeeze()==1],bins=20)\n",
    "sns.distplot(unseen_positives_preds,bins=20)\n",
    "sns.distplot(dinuc_shuff_positives_preds,bins=20)\n",
    "sns.distplot(random_shuff_positives_preds,bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save space by deleting the validation data\n",
    "#del valid_data\n",
    "#del valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
